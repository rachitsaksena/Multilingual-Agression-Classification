{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Normalization for Hindi & Bangla Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas                        as pd\n",
    "import numpy                         as np\n",
    "import math\n",
    "\n",
    "import seaborn                       as sns\n",
    "import matplotlib.pyplot             as plt\n",
    "\n",
    "from googletrans                     import Translator\n",
    "translator = Translator()\n",
    "\n",
    "from collections                     import Counter\n",
    "from nltk.corpus                     import stopwords\n",
    "import itertools\n",
    "import re\n",
    "import httpx\n",
    "timeout = httpx.Timeout(5) # 1 second timeout\n",
    "\n",
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_monolingual(df, dest):\n",
    "    monol = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sentence=df.iloc[i, 1]\n",
    "#         \" \".join(sentence.split().apply(lambda x : translator.translate(x, src=\"hi\", dest=\"hi\").text.lower()))\n",
    "        monol.append(\" \".join([translator.translate(x, dest=dest, timeout=timeout).text.lower() for x in sentence.split()]))\n",
    "    df[\"normalized lexicon\"] = monol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(df, x, y, title, label, ylabel, dim, orient = \"v\", ci = False, hue = None):\n",
    "    \n",
    "    plt.figure(figsize = dim, facecolor = \"white\")\n",
    "    sns.barplot(x = x, y = y, data = df, orient = orient, ci = ci, hue = hue)\n",
    "    plt.title(f\"{title}\", size = 18)\n",
    "    plt.xlabel(f\"{label}\", size = 16)\n",
    "    plt.ylabel(f\"{ylabel}\", size = 16)\n",
    "    plt.xticks(size = 14)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stopwords(url):\n",
    "    stop = pd.read_csv(url, sep='\\n', header=0, names=['words'])\n",
    "    stop = stop['words'].values.tolist()\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stopwordsiso import stopwords\n",
    "# bangla_stopwords = stopwords('bn')\n",
    "\n",
    "hinglish_stopwords = fetch_stopwords('https://raw.githubusercontent.com/TrigonaMinima/HinglishNLP/master/data/assets/stop_hinglish')\n",
    "english_stopwords = set(stopwords.words('english') + hinglish_stopwords)\n",
    "hindi_stopwords = set(fetch_stopwords('https://raw.githubusercontent.com/TrigonaMinima/HinglishNLP/master/data/assets/stop_hindi'))\n",
    "bangla_stopwords = set(fetch_stopwords('https://raw.githubusercontent.com/rachitsaksena/Multilingual-Agression-Classification/master/Cache/Models/bangla%20stop.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_dict = {'en': english_stopwords,\n",
    "             'hi': hindi_stopwords,\n",
    "             'bn': bangla_stopwords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001F923\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, lang):\n",
    "    stop_words = stop_dict[lang]\n",
    "    df['monolingual'] = df[\"normalized lexicon\"]\n",
    "    for i in range(df.shape[0]):\n",
    "        sentence = df[\"normalized lexicon\"].iloc[i]\n",
    "        sentence = deEmojify(sentence)\n",
    "        sentence = re.sub(r\"([.!?|])\", r\"\", sentence)\n",
    "        sentence = re.sub(r'[/(){}\\[\\]\\|@,;:.]', r'', str(sentence))\n",
    "#         sentence = re.sub(r\"[^a-z]+\", r\" \", sentence)\n",
    "        sentence = ' '.join(word for word in sentence.split() if word not in stop_words and len(word)>2)\n",
    "        df['monolingual'].iloc[i] = sentence\n",
    "#     df['tokenized'] = [tokenizer.tokenize(text) for text in df['clean text']] #problem\n",
    "    df['tokenized'] = [text.split() for text in df['clean text']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HINDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C4.131</td>\n",
       "      <td>Bollywood film dekhne ke samay logic ghar mein...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4.638</td>\n",
       "      <td>Chutiya movie...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C38.598</td>\n",
       "      <td>Us jaat bnde ka khene ka matlab tha mar daluga...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.2101.1</td>\n",
       "      <td>@Feminism Is CANCER *un feminist yeh sahi hai ...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C29.14.2</td>\n",
       "      <td>Amrit Anand अब तो जुड़े ही है उनको बोलो जुड़ने</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               Text Sub-task A  \\\n",
       "0     C4.131  Bollywood film dekhne ke samay logic ghar mein...        NAG   \n",
       "1     C4.638                                   Chutiya movie...        NAG   \n",
       "2    C38.598  Us jaat bnde ka khene ka matlab tha mar daluga...        OAG   \n",
       "3  C4.2101.1  @Feminism Is CANCER *un feminist yeh sahi hai ...        OAG   \n",
       "4   C29.14.2       Amrit Anand अब तो जुड़े ही है उनको बोलो जुड़ने        NAG   \n",
       "\n",
       "  Sub-task B  \n",
       "0       NGEN  \n",
       "1       NGEN  \n",
       "2       NGEN  \n",
       "3       NGEN  \n",
       "4       NGEN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hin_train = pd.read_csv('Data/trac2_hin_train.csv')\n",
    "hin_test = pd.read_csv('Data/trac2_hin_dev.csv')\n",
    "hin = hin_train.append(hin_test)\n",
    "hin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_monolingual(hin, dest='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskA_df = (hin.set_index(['ID', 'Sub-task A']).count(level='Sub-task A'))\n",
    "\n",
    "barplot(df = taskA_df,\n",
    "        x = taskA_df.index,\n",
    "        y = \"Text\",\n",
    "        title = \"Distribution of Classes\",\n",
    "        label = \"Aggression Annotation\",\n",
    "        ylabel = \"Count\",\n",
    "        dim = (20, 5))\n",
    "\n",
    "print('HINDI')\n",
    "print(hin['Sub-task A'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(hin, 'hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hin.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hin.to_csv('./Data/cleaned hindi', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BANGLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_train = pd.read_csv('Data/trac2_iben_train.csv')\n",
    "ben_test = pd.read_csv('Data/trac2_iben_dev.csv')\n",
    "ben = ben_train.append(ben_test)\n",
    "ben.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_monolingual(ben, dest='bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskA_df = (ben.set_index(['ID', 'Sub-task A']).count(level='Sub-task A'))\n",
    "\n",
    "barplot(df = taskA_df,\n",
    "        x = taskA_df.index,\n",
    "        y = \"Text\",\n",
    "        title = \"Distribution of Classes\",\n",
    "        label = \"Aggression Annotation\",\n",
    "        ylabel = \"Count\",\n",
    "        dim = (20, 5))\n",
    "\n",
    "print('BANGLA')\n",
    "print(ben['Sub-task A'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(ben, 'bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben.to_csv('./Data/cleaned bangla', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
