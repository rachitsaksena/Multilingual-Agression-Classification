{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                       as pd\n",
    "import numpy                        as np\n",
    "import torch\n",
    "import torch.nn                     as nn\n",
    "import torch.nn.functional          as F\n",
    "import torch.optim                  as optim\n",
    "# from torchtext                      import data\n",
    "# import torchtext\n",
    "import re\n",
    "from sklearn.metrics                import roc_auc_score\n",
    "from sklearn.metrics                import roc_curve, auc\n",
    "import matplotlib.pyplot            as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>B</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>normalized lexicon</th>\n",
       "      <th>monolingual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>next part</td>\n",
       "      <td>['next', 'part']</td>\n",
       "      <td>['next', 'part']</td>\n",
       "      <td>next part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>iii8mllllllm mdxfvb8o90lplppi0005</td>\n",
       "      <td>['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']</td>\n",
       "      <td>['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']</td>\n",
       "      <td>iii 8mllllllm mdxfvb 8o90lplppi0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>osm vedio make vedios</td>\n",
       "      <td>['osm', 'vedio', 'make', 'vedios']</td>\n",
       "      <td>['osm', 'osf', 'vedic', 'make', 'videos']</td>\n",
       "      <td>osm osf vedic make videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>what fuck this? respect shwetabh watching vide...</td>\n",
       "      <td>['what', 'fuck', 'this', '?', 'respect', 'shwe...</td>\n",
       "      <td>['what', 'fuck', 'fuck', 'this', '?', 'respect...</td>\n",
       "      <td>what fuck fuck this ? respect respect whitish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>concerned authorities bring arundathi roy type...</td>\n",
       "      <td>['concerned', 'authorities', 'bring', 'arundat...</td>\n",
       "      <td>['concerned', 'authorities', 'bring', 'arundat...</td>\n",
       "      <td>concerned authorities bring arundathi roy roy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ID                                               Text  \\\n",
       "0           0  C45.451                                          Next part   \n",
       "1           1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005   \n",
       "2           2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...   \n",
       "3           3  C4.1961  What the fuck was this? I respect shwetabh and...   \n",
       "4           4  C10.153  Concerned authorities should bring arundathi R...   \n",
       "\n",
       "  label     B                                              clean  \\\n",
       "0   NAG  NGEN                                          next part   \n",
       "1   NAG  NGEN                  iii8mllllllm mdxfvb8o90lplppi0005   \n",
       "2   NAG  NGEN                              osm vedio make vedios   \n",
       "3   NAG  NGEN  what fuck this? respect shwetabh watching vide...   \n",
       "4   NAG  NGEN  concerned authorities bring arundathi roy type...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                   ['next', 'part']   \n",
       "1   ['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']   \n",
       "2                 ['osm', 'vedio', 'make', 'vedios']   \n",
       "3  ['what', 'fuck', 'this', '?', 'respect', 'shwe...   \n",
       "4  ['concerned', 'authorities', 'bring', 'arundat...   \n",
       "\n",
       "                                  normalized lexicon  \\\n",
       "0                                   ['next', 'part']   \n",
       "1   ['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']   \n",
       "2          ['osm', 'osf', 'vedic', 'make', 'videos']   \n",
       "3  ['what', 'fuck', 'fuck', 'this', '?', 'respect...   \n",
       "4  ['concerned', 'authorities', 'bring', 'arundat...   \n",
       "\n",
       "                                         monolingual  \n",
       "0                                          next part  \n",
       "1                iii 8mllllllm mdxfvb 8o90lplppi0005  \n",
       "2                          osm osf vedic make videos  \n",
       "3  what fuck fuck this ? respect respect whitish ...  \n",
       "4  concerned authorities bring arundathi roy roy ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './Data/cleaned english.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.rename(columns = {'Unnamed: 0': 'Unnamed: 0', 'ID': 'ID', 'Text': 'Text', 'Sub-task A': 'label', 'Sub-task B': 'B', 'clean text': 'clean', 'tokenized': 'tokenized', 'normalized lexicon': 'normalized lexicon', 'monolingual': 'monolingual'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    x = df.Text.iloc[i]\n",
    "    if len(x) <= 0:\n",
    "        print(df.Text.iloc[i])\n",
    "        df.Text.iloc[i] = None\n",
    "        \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               Next part\n",
       "1                      Iii8mllllllm\\nMdxfvb8o90lplppi0005\n",
       "2       🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...\n",
       "3       What the fuck was this? I respect shwetabh and...\n",
       "4       Concerned authorities should bring arundathi R...\n",
       "                              ...                        \n",
       "4258    Abey loudey Arnab... Did u ever see the vedios...\n",
       "4259    Arundati is very rich where she get money who ...\n",
       "4260    People may criticize Pratik Borade by saying t...\n",
       "4261                                       @Naaz Sk hello\n",
       "4262    We want to read your book sir, please make it ...\n",
       "Name: Text, Length: 4205, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b89f653de386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spacy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True, lower = True, )\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True, lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LABEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-35030262005c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'monolingual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTabularDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LABEL' is not defined"
     ]
    }
   ],
   "source": [
    "fields = [(None, None), (None, None), ('Text', TEXT), ('label', LABEL), (None, None), (None, None), (None, None), (None, None), (None, None)]\n",
    "training_data=data.TabularDataset(path = path, format = 'csv', fields = fields, skip_header = True)\n",
    "\n",
    "print(vars(training_data.examples[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = training_data.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.Vectors('wiki-news-300d-1M.vec', cache = './Cache/Embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of topic vocab: 2012\n",
      "Size of label vocab: 3\n",
      "[('movie', 816), ('kabir', 494), ('singh', 431), ('video', 375), ('review', 364), ('?', 297), ('india', 273), ('nice', 259), ('man', 256), ('watch', 237), ('sir', 232)]\n",
      "[('nag', 2373), ('cag', 316), ('oag', 295)]\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x11ff90160>>, {'<unk>': 0, '<pad>': 1, 'movie': 2, 'kabir': 3, 'singh': 4, 'video': 5, 'review': 6, '?': 7, 'india': 8, 'nice': 9, 'man': 10, 'watch': 11, 'sir': 12, 'a': 13, 'love': 14, 'character': 15, 'time': 16, 'great': 17, '!': 18, 'wrong': 19, 'you': 20, 'feminism': 21, 'the': 22, '\"': 23, 'indian': 24, 't': 25, 'god': 26, 'hollywood': 27, 'this': 28, 'roy': 29, '-': 30, 'movies': 31, 'arundhati': 32, 'feminist': 33, 'story': 34, 'and': 35, 'respect': 36, '=': 37, 'film': 38, '*': 39, 'bollywood': 40, 'brother': 41, 'arjun': 42, 'life': 43, 'agree': 44, 's': 45, 'good': 46, 'guy': 47, 'she': 48, 'make': 49, 'reddy': 50, 'couture': 51, 'fuck': 52, 'youtube': 53, 'girl': 54, 'gay': 55, 'shit': 56, 'videos': 57, 'view': 58, 'women': 59, 'channel': 60, 'feminists': 61, 'joker': 62, 'right': 63, 'shahid': 64, '%': 65, 'but': 66, 'world': 67, 'super': 68, 'men': 69, 'liberal': 70, \"'\": 71, 'bro': 72, 'v': 73, 'that': 74, 'person': 75, 'what': 76, 'best': 77, 'army': 78, 'country': 79, 'lady': 80, 'real': 81, 'its': 82, 'problem': 83, 'give': 84, 'ibm': 85, 'they': 86, 'hero': 87, 'liberals': 88, 'support': 89, 'point': 90, 'govt': 91, 'watching': 92, '#': 93, 'pratik': 94, 'ratio': 95, 'stupid': 96, 'law': 97, 'made': 98, 'understand': 99, 'girls': 100, 'totally': 101, 'big': 102, 'do': 103, 'indians': 104, 'reviews': 105, 'sex': 106, 'why': 107, 'woman': 108, 'father': 109, 'guys': 110, '&': 111, 'male': 112, 'please': 113, 'speak': 114, 'very': 115, 'watched': 116, 'called': 117, 'kind': 118, 'modi': 119, 'ran': 120, 'arab': 121, 'society': 122, 'act': 123, 'amazing': 124, 'awesome': 125, 'bhai': 126, 'fact': 127, 'thai': 128, 'arnab': 129, 'hate': 130, 'anti': 131, 'not': 132, 'pakistan': 133, 'ranu': 134, 'there': 135, 'things': 136, 'generation': 137, 'job': 138, 'salute': 139, 'superb': 140, 'acting': 141, 'comresults': 142, 'search_query': 143, 'talk': 144, 'yes': 145, 'call': 146, 'coldwatch': 147, 'english': 148, 'follow': 149, 'free': 150, 'kapoor': 151, 'opinion': 152, 'comment': 153, 'debate': 154, 'family': 155, 'making': 156, 'people': 157, 'social': 158, 'thanks': 159, 'feel': 160, 'show': 161, '<': 162, '>': 163, 'boy': 164, 'court': 165, 'nrc': 166, 'thank': 167, 'characters': 168, 'how': 169, 'national': 170, 'ppl': 171, 'reply': 172, 'shirt': 173, 'well': 174, 'agenda': 175, 'bless': 176, 'dada': 177, 'don': 178, 'jahangir': 179, 'live': 180, 'mad': 181, \"n't\": 182, 'points': 183, 'rights': 184, 'truth': 185, 'first': 186, 'httpsyoutu': 187, 'put': 188, 'state': 189, 'stop': 190, 'these': 191, 'violence': 192, 'work': 193, 'absolutely': 194, 'answer': 195, 'end': 196, 'face': 197, 'female': 198, 'just': 199, 'lesbian': 200, 'mind': 201, 'now': 202, 'preeti': 203, 'scene': 204, 'south': 205, 'talking': 206, 'year': 207, 'your': 208, 'ा': 209, \"'s\": 210, 'all': 211, 'back': 212, 'different': 213, 'kumar': 214, 'loved': 215, 'one': 216, 'pseudo': 217, 'reality': 218, 'waiting': 219, 'who': 220, 'wow': 221, 'caa': 222, 'fake': 223, 'finally': 224, 'friend': 225, 'government': 226, 'hindi': 227, 'honest': 228, 'it': 229, 'message': 230, 'plc': 231, 'plz': 232, 'positive': 233, 'read': 234, 'toxic': 235, 'are': 236, 'companion': 237, 'future': 238, 'long': 239, 'lot': 240, 'means': 241, 'part': 242, 'range': 243, 'relationship': 244, 'shown': 245, 'views': 246, 'whitish': 247, 'bjp': 248, 'college': 249, 'congress': 250, 'day': 251, 'equality': 252, 'his': 253, 'lol': 254, 'news': 255, 'police': 256, 'sense': 257, 'shitty': 258, 'sucharita': 259, 'telugu': 260, 'thoughts': 261, 'western': 262, 'when': 263, '100': 264, 'at': 265, 'boss': 266, 'boys': 267, 'correct': 268, 'gender': 269, 'media': 270, 'money': 271, 'negative': 272, 'years': 273, 'youth': 274, 'am': 275, 'behavior': 276, 'bullshit': 277, 'change': 278, 'culture': 279, 'false': 280, 'for': 281, 'fucker': 282, 'giving': 283, 'hell': 284, 'hindus': 285, 'human': 286, 'iam': 287, 'nt': 288, 'true': 289, 'urban': 290, 'bill': 291, 'constitution': 292, 'films': 293, 'find': 294, 'homosexual': 295, 'homosexuality': 296, 'idiot': 297, 'left': 298, 'like': 299, 'marriage': 300, 'masculinity': 301, 'shwetabh': 302, 'away': 303, 'bitch': 304, 'case': 305, 'chutiya': 306, 'concept': 307, 'crap': 308, 'created': 309, 'disgusting': 310, 'dislikes': 311, 'fucking': 312, 'hai': 313, 'hope': 314, 'issues': 315, 'judge': 316, 'only': 317, 'parents': 318, 'perfect': 319, 'proud': 320, 'randi': 321, 'reason': 322, 'shame': 323, 'start': 324, 'times': 325, 'war': 326, '\\u200d': 327, '.': 328, '498a': 329, 'allowed': 330, 'billa': 331, 'care': 332, 'crime': 333, 'did': 334, 'dog': 335, 'friends': 336, 'is': 337, 'mandal': 338, 'mental': 339, 'nature': 340, 'public': 341, 'r98': 342, 'ranga': 343, 'shows': 344, 'type': 345, 'word': 346, 'analysis': 347, 'audience': 348, 'beautiful': 349, 'behaviour': 350, 'book': 351, 'can': 352, 'control': 353, 'cool': 354, 'dis': 355, 'fan': 356, 'funny': 357, 'happy': 358, 'hard': 359, 'hindu': 360, 'home': 361, 'kung': 362, 'likes': 363, 'luck': 364, 'masterpiece': 365, 'modern': 366, 'nation': 367, 'pls': 368, 'reviewer': 369, 'send': 370, 'sexual': 371, 'sick': 372, 'single': 373, 'speech': 374, 'today': 375, 'wanted': 376, 'whatsapp': 377, 'abuse': 378, 'appreciate': 379, 'biggest': 380, 'body': 381, 'cinema': 382, 'dear': 383, 'destructive': 384, 'equal': 385, 'freedom': 386, 'garbage': 387, 'kasturi': 388, 'learn': 389, 'least': 390, 'pasture': 391, 'really': 392, 'share': 393, 'side': 394, 'situation': 395, 'sorry': 396, 'speaking': 397, 'will': 398, '0': 399, 'atleast': 400, 'changed': 401, 'coming': 402, 'completely': 403, 'coz': 404, 'difference': 405, 'even': 406, 'every': 407, 'hit': 408, 'house': 409, 'instead': 410, 'intellectual': 411, 'jail': 412, 'justify': 413, 'lgb': 414, 'lgbt': 415, 'nupur': 416, 'of': 417, 'open': 418, 'perspective': 419, 'play': 420, 'rape': 421, 'rss': 422, 'sharma': 423, 'showing': 424, 'tamil': 425, 'wife': 426, '+': 427, 'agreed': 428, 'attitude': 429, 'based': 430, 'days': 431, 'delhi': 432, 'deserve': 433, 'director': 434, 'genuine': 435, 'husband': 436, 'industry': 437, 'jai': 438, 'language': 439, 'laws': 440, 'legal': 441, 'lost': 442, 'n_zmfqmzos': 443, 'pretty': 444, 'problems': 445, 'realistic': 446, 'sanders': 447, 'shots': 448, 'simple': 449, 'some': 450, 'team': 451, 'till': 452, 'wedding': 453, 'accept': 454, 'actor': 455, 'alcoholic': 456, 'alert': 457, 'born': 458, 'bring': 459, 'consent': 460, 'content': 461, 'copy': 462, 'dangerous': 463, 'devil': 464, 'didi': 465, 'domestic': 466, 'dowry': 467, 'due': 468, 'emotions': 469, 'enjoy': 470, 'felt': 471, 'get': 472, 'go': 473, 'hear': 474, 'her': 475, 'i': 476, 'immediately': 477, 'information': 478, 'issue': 479, 'keep': 480, 'leave': 481, 'm': 482, 'makes': 483, 'married': 484, 'most': 485, 'move': 486, 'msg': 487, 'nailed': 488, 'nor': 489, 'number': 490, 'o': 491, 'opinions': 492, 'population': 493, 'sardar': 494, 'section': 495, 'series': 496, 'song': 497, 'stay': 498, 'such': 499, 'supreme': 500, 'telling': 501, 'usa': 502, 'vai': 503, 'wanna': 504, 'with': 505, 'words': 506, 'worst': 507, '🤗': 508, '377': 509, 'actors': 510, 'after': 511, 'believe': 512, 'bloody': 513, 'china': 514, 'course': 515, 'drugs': 516, 'dumb': 517, 'gays': 518, 'journalist': 519, 'khan': 520, 'kiss': 521, 'knew': 522, 'level': 523, 'meaning': 524, 'mr': 525, 'natural': 526, 'night': 527, 'npr': 528, 'outta': 529, 'personal': 530, 'place': 531, 'poor': 532, 'possible': 533, 'rajdeep': 534, 'shut': 535, 'sister': 536, 'spreading': 537, 'stand': 538, 'straight': 539, 'top': 540, 'voice': 541, 'was': 542, 'waste': 543, \"you'se\": 544, 'আ': 545, 'action': 546, 'aha': 547, 'anger': 548, 'any': 549, 'arrested': 550, 'ass': 551, 'bangladesh': 552, 'bastard': 553, 'bed': 554, 'bit': 555, 'check': 556, 'club': 557, 'damn': 558, 'dark': 559, 'death': 560, 'doctor': 561, 'drama': 562, 'drinking': 563, 'emotional': 564, 'everyone': 565, 'excellent': 566, 'explanation': 567, 'eye': 568, 'guess': 569, 'hand': 570, 'heroine': 571, 'homosexuals': 572, 'hot': 573, 'idiots': 574, 'imagine': 575, 'lead': 576, 'lots': 577, 'moron': 578, 'mouth': 579, 'new': 580, 'north': 581, 'our': 582, 'prize': 583, 'rapist': 584, 'rat': 585, 'ready': 586, 'responsibility': 587, 'same': 588, 'shah': 589, 'shoes': 590, 'slap': 591, 'smart': 592, 'soo': 593, 'suffer': 594, 'understanding': 595, 'up': 596, 'values': 597, 'yar': 598, 'alcohol': 599, 'also': 600, 'anima': 601, 'arundati': 602, 'asked': 603, 'bible': 604, 'borade': 605, 'child': 606, 'clear': 607, 'comments': 608, 'common': 609, 'countries': 610, 'deepika': 611, 'earth': 612, 'entertainment': 613, 'expect': 614, 'f': 615, 'feeling': 616, 'flawed': 617, 'fu': 618, 'full': 619, 'gandhi': 620, 'gave': 621, 'hats': 622, 'high': 623, 'husbands': 624, 'ideas': 625, 'killed': 626, 'kutta': 627, 'leftist': 628, 'let': 629, 'lie': 630, 'logic': 631, 'madam': 632, 'mensural': 633, 'moral': 634, 'more': 635, 'name': 636, 'need': 637, 'no': 638, 'non': 639, 'openly': 640, 'opposite': 641, 'order': 642, 'peoples': 643, 'political': 644, 'promote': 645, 'released': 646, 'request': 647, 'sad': 648, 'scenes': 649, 'seriously': 650, 'slapped': 651, 'songs': 652, 'started': 653, 'stopped': 654, 'su': 655, 'takes': 656, 'taking': 657, 'taxi': 658, 'told': 659, 'typical': 660, 'vijay': 661, 'wish': 662, 'yaar': 663, 'young': 664, '~': 665, '्': 666, '\\\\': 667, 'actions': 668, 'arrest': 669, 'bad': 670, 'basic': 671, 'because': 672, 'boycott': 673, 'bravo': 674, 'break': 675, 'breakup': 676, 'broken': 677, 'calling': 678, 'cheap': 679, 'choice': 680, 'chopra': 681, 'class': 682, 'direction': 683, 'directors': 684, 'dogs': 685, 'dude': 686, 'education': 687, 'entire': 688, 'especially': 689, 'explain': 690, 'fans': 691, 'forget': 692, 'found': 693, 'gang': 694, 'grey': 695, 'group': 696, 'grow': 697, 'happen': 698, 'happened': 699, 'heroic': 700, 'hii': 701, 'huge': 702, 'ie': 703, 'illiterate': 704, 'injustice': 705, 'innocent': 706, 'inside': 707, 'interested': 708, 'intro': 709, 'kashmir': 710, 'line': 711, 'list': 712, 'literally': 713, 'living': 714, 'loves': 715, 'medical': 716, 'mensutra': 717, 'mislead': 718, 'misogyny': 719, 'monday': 720, 'multiple': 721, 'muslim': 722, 'needed': 723, 'nonsense': 724, 'normal': 725, 'nothing': 726, 'office': 727, 'omg': 728, 'pain': 729, 'partner': 730, 'pathetic': 731, 'personally': 732, 'physical': 733, 'played': 734, 'politics': 735, 'power': 736, 'road': 737, 'role': 738, 'said': 739, 'shankar': 740, 'study': 741, 'system': 742, 'thankyou': 743, 'then': 744, 'threat': 745, 'topic': 746, 'topper': 747, 'tyagi': 748, 'u': 749, 'write': 750, 'youtuber': 751, '_': 752, 'abusive': 753, 'ache': 754, 'addict': 755, 'age': 756, 'area': 757, 'arundathi': 758, 'b': 759, 'baby': 760, 'basically': 761, 'beard': 762, 'being': 763, 'better': 764, 'black': 765, 'blood': 766, 'box': 767, 'brain': 768, 'cancer': 769, 'citizenship': 770, 'complete': 771, 'consider': 772, 'continue': 773, 'criminal': 774, 'debates': 775, 'deep': 776, 'depends': 777, 'destroyed': 778, 'dint': 779, 'everything': 780, 'exactly': 781, 'expecting': 782, 'facts': 783, 'fault': 784, 'fight': 785, 'from': 786, 'fun': 787, 'half': 788, 'hated': 789, 'have': 790, 'hello': 791, 'here': 792, 'hey': 793, 'hypocrisy': 794, 'ignorant': 795, 'individual': 796, 'influenced': 797, 'inspiration': 798, 'j': 799, 'knife': 800, 'know': 801, 'lies': 802, 'listen': 803, 'lives': 804, 'logical': 805, 'marry': 806, 'matter': 807, 'members': 808, 'mentally': 809, 'misandrists': 810, 'misleading': 811, 'months': 812, 'mother': 813, 'nec': 814, 'nyc': 815, 'osf': 816, 'osm': 817, 'paid': 818, 'partners': 819, 'peace': 820, 'performance': 821, 'pleasure': 822, 'plzz': 823, 'promoting': 824, 'prostitute': 825, 'random': 826, 'religion': 827, 'remember': 828, 'rock': 829, 'rubbish': 830, 'run': 831, 'ryt': 832, 'save': 833, 'short': 834, 'slapping': 835, 'so': 836, 'sort': 837, 'spoiler': 838, 'spread': 839, 'stars': 840, 'starting': 841, 'step': 842, 'student': 843, 'stuff': 844, 'suicide': 845, 'supporting': 846, 'take': 847, 'teach': 848, 'their': 849, 'thinks': 850, 'total': 851, 'trailer': 852, 'ugly': 853, 'value': 854, 'vedas': 855, 'viewers': 856, 'wonder': 857, 'wwf': 858, 'এ': 859, '1st': 860, 'about': 861, 'absolute': 862, 'abusing': 863, 'accepted': 864, 'activities': 865, 'acts': 866, 'actual': 867, 'actually': 868, 'ago': 869, 'asshole': 870, 'available': 871, 'banned': 872, 'barman': 873, 'bars': 874, 'bashing': 875, 'bc': 876, 'bcoz': 877, 'bcz': 878, 'behave': 879, 'beings': 880, 'bitches': 881, 'blowing': 882, 'books': 883, 'boz': 884, 'bull': 885, 'burn': 886, 'c': 887, 'cares': 888, 'census': 889, 'citizens': 890, 'committed': 891, 'community': 892, 'cut': 893, 'decent': 894, 'defend': 895, 'democracy': 896, 'developed': 897, 'does': 898, 'dum': 899, 'ending': 900, 'expose': 901, 'fabulous': 902, 'fantastic': 903, 'feelings': 904, 'fiction': 905, 'fighting': 906, 'file': 907, 'final': 908, 'forcing': 909, 'glad': 910, 'glorifying': 911, 'gourami': 912, 'gupta': 913, 'happening': 914, 'harsh': 915, 'heaven': 916, 'hind': 917, 'honestly': 918, 'hypocrite': 919, 'idea': 920, 'ill': 921, 'illegal': 922, 'illogical': 923, 'impact': 924, 'in': 925, 'inspire': 926, 'interest': 927, 'islam': 928, 'item': 929, 'join': 930, 'joke': 931, 'kissing': 932, 'knowledge': 933, 'krishna': 934, 'kungfu': 935, 'lesbians': 936, 'liberalism': 937, 'lord': 938, 'lover': 939, 'loving': 940, 'lutyens': 941, 'major': 942, 'may': 943, 'meant': 944, 'minded': 945, 'mission': 946, 'na': 947, 'naam': 948, 'nam': 949, 'named': 950, 'others': 951, 'pak': 952, 'pakistani': 953, 'particular': 954, 'personality': 955, 'portray': 956, 'ppls': 957, 'process': 958, 'program': 959, 'propaganda': 960, 'protagonist': 961, 'publicity': 962, 'punished': 963, 'punjabi': 964, 'purpose': 965, 'question': 966, 'raja': 967, 'raw': 968, 'reaction': 969, 'realize': 970, 'remake': 971, 'responsible': 972, 'rest': 973, 'sanjo': 974, 'screen': 975, 'self': 976, 'shouting': 977, 'showed': 978, 'simply': 979, 'since': 980, 'singer': 981, 'sound': 982, 'st': 983, 'starts': 984, 'stories': 985, 'submissive': 986, 'subscribed': 987, 'subscribers': 988, 'sugar': 989, 'surgeon': 990, 'think': 991, 'those': 992, 'too': 993, 'uncle': 994, 'universe': 995, 'valid': 996, 'valley': 997, 'van': 998, 'vere': 999, 'vital': 1000, 'wave': 1001, 'west': 1002, 'where': 1003, 'worth': 1004, 'written': 1005, 'yea': 1006, 'yesterday': 1007, '\\U0001f92d': 1008, '09777070288': 1009, '30': 1010, 'accent': 1011, 'according': 1012, 'address': 1013, 'affected': 1014, 'anchor': 1015, 'angry': 1016, 'anymore': 1017, 'arguments': 1018, 'ban': 1019, 'bastards': 1020, 'bear': 1021, 'beware': 1022, 'bhubaneswar': 1023, 'bight': 1024, 'bisht': 1025, 'blockbuster': 1026, 'bottom': 1027, 'brought': 1028, 'build': 1029, 'business': 1030, 'cases': 1031, 'charecter': 1032, 'close': 1033, 'come': 1034, 'comedy': 1035, 'consequences': 1036, 'contact': 1037, 'core': 1038, 'crazy': 1039, 'create': 1040, 'criminals': 1041, 'critics': 1042, 'current': 1043, 'cute': 1044, 'dead': 1045, 'definitely': 1046, 'depression': 1047, 'deserves': 1048, 'development': 1049, 'deviation': 1050, 'dialogues': 1051, 'dick': 1052, 'didn': 1053, 'die': 1054, 'disagree': 1055, 'disappointed': 1056, 'dish': 1057, 'dna': 1058, 'drug': 1059, 'dubai': 1060, 'eagerly': 1061, 'effort': 1062, 'encourage': 1063, 'exposed': 1064, 'extent': 1065, 'eyes': 1066, 'fall': 1067, 'families': 1068, 'fear': 1069, 'feminazi': 1070, 'fire': 1071, 'fool': 1072, 'forces': 1073, 'form': 1074, 'front': 1075, 'fucked': 1076, 'gangs': 1077, 'genius': 1078, 'girlfriend': 1079, 'goal': 1080, 'goi': 1081, 'goodness': 1082, 'habit': 1083, 'has': 1084, 'head': 1085, 'heart': 1086, 'holy': 1087, 'homo': 1088, 'hours': 1089, 'hurt': 1090, 'independent': 1091, 'influence': 1092, 'inspired': 1093, 'inspiring': 1094, 'intelligent': 1095, 'interesting': 1096, 'j2j5sssp5yq': 1097, 'judging': 1098, 'justice': 1099, 'k': 1100, 'kapil': 1101, 'kick': 1102, 'kids': 1103, 'killing': 1104, 'lack': 1105, 'land': 1106, 'late': 1107, 'look': 1108, 'loose': 1109, 'lunatic': 1110, 'madarchod': 1111, 'mature': 1112, 'meet': 1113, 'min': 1114, 'mindset': 1115, 'minutes': 1116, 'misogynist': 1117, 'morning': 1118, 'movi': 1119, 'oppose': 1120, 'option': 1121, 'other': 1122, 'pander': 1123, 'parts': 1124, 'path': 1125, 'persons': 1126, 'piece': 1127, 'pit': 1128, 'pity': 1129, 'planet': 1130, 'playing': 1131, 'pro': 1132, 'progress': 1133, 'proof': 1134, 'prove': 1135, 'provide': 1136, 'pure': 1137, 'putting': 1138, 'ram': 1139, 'randy': 1140, 'raped': 1141, 'realised': 1142, 'related': 1143, 'religious': 1144, 'rich': 1145, 'room': 1146, 'ruining': 1147, 'rule': 1148, 'sail': 1149, 'sane': 1150, 'sara': 1151, 'savage': 1152, 'say': 1153, 'saying': 1154, 'see': 1155, 'sell': 1156, 'shallow': 1157, 'sides': 1158, 'silent': 1159, 'sing': 1160, 'slaps': 1161, 'soldiers': 1162, 'someone': 1163, 'spoke': 1164, 'still': 1165, 'students': 1166, 'studying': 1167, 'supported': 1168, 'surprised': 1169, 'taught': 1170, 'terrorism': 1171, 'them': 1172, 'thing': 1173, 'though': 1174, 'three': 1175, 'throw': 1176, 'toilets': 1177, 'topics': 1178, 'transgenes': 1179, 'unable': 1180, 've': 1181, 'vedic': 1182, 'version': 1183, 'victim': 1184, 'vipul': 1185, 'want': 1186, 'white': 1187, 'womens': 1188, 'worse': 1189, 'yeah': 1190, 'yess': 1191, 'া': 1192, 'accused': 1193, 'actress': 1194, 'add': 1195, 'affect': 1196, 'agar': 1197, 'aggression': 1198, 'air': 1199, 'akshay': 1200, 'allah': 1201, 'allowing': 1202, 'always': 1203, 'amazon': 1204, 'amit': 1205, 'anyone': 1206, 'apparently': 1207, 'apu': 1208, 'armed': 1209, 'arms': 1210, 'aspect': 1211, 'assam': 1212, 'assay': 1213, 'attention': 1214, 'aware': 1215, 'background': 1216, 'banana': 1217, 'before': 1218, 'beggar': 1219, 'benefit': 1220, 'bengal': 1221, 'bhi': 1222, 'bigger': 1223, 'biography': 1224, 'birth': 1225, 'blind': 1226, 'bob': 1227, 'bothered': 1228, 'brave': 1229, 'british': 1230, 'broo': 1231, 'brow': 1232, 'buy': 1233, 'camera': 1234, 'canada': 1235, 'captain': 1236, 'career': 1237, 'catch': 1238, 'chance': 1239, 'changes': 1240, 'channels': 1241, 'civilization': 1242, 'climax': 1243, 'coll': 1244, 'commenting': 1245, 'commission': 1246, 'commit': 1247, 'complex': 1248, 'conduct': 1249, 'conjuring': 1250, 'conservative': 1251, 'considered': 1252, 'contents': 1253, 'convey': 1254, 'count': 1255, 'counter': 1256, 'crimes': 1257, 'critic': 1258, 'critical': 1259, 'criticised': 1260, 'cry': 1261, 'crying': 1262, 'cultural': 1263, 'cunning': 1264, 'daisy': 1265, 'damage': 1266, 'dass': 1267, 'data': 1268, 'date': 1269, 'daughter': 1270, 'david': 1271, 'deal': 1272, 'decided': 1273, 'defence': 1274, 'definition': 1275, 'degree': 1276, 'demo': 1277, 'designer': 1278, 'despite': 1279, 'destruction': 1280, 'dil': 1281, 'directed': 1282, 'discrimination': 1283, 'dislike': 1284, 'dnt': 1285, 'drink': 1286, 'dump': 1287, 'earlier': 1288, 'ect': 1289, 'educated': 1290, 'ego': 1291, 'encounter': 1292, 'ended': 1293, 'epic': 1294, 'etc': 1295, 'everyday': 1296, 'exist': 1297, 'expected': 1298, 'experience': 1299, 'explained': 1300, 'expression': 1301, 'extremely': 1302, 'far': 1303, 'favourite': 1304, 'feels': 1305, 'filled': 1306, 'focus': 1307, 'followers': 1308, 'foolish': 1309, 'forced': 1310, 'frankly': 1311, 'fully': 1312, 'glorify': 1313, 'gon': 1314, 'gud': 1315, 'guts': 1316, 'gym': 1317, 'ha': 1318, 'habits': 1319, 'hahahaha': 1320, 'happily': 1321, 'harm': 1322, 'hatred': 1323, 'heard': 1324, 'history': 1325, 'homophobia': 1326, 'hospital': 1327, 'hostel': 1328, 'httpswww': 1329, 'humana': 1330, 'humanity': 1331, 'hussain': 1332, 'if': 1333, 'ignore': 1334, 'immature': 1335, 'important': 1336, 'indus': 1337, 'interview': 1338, 'intolerant': 1339, 'irrespective': 1340, 'ishtar': 1341, 'kasthuri': 1342, 'khurana': 1343, 'kid': 1344, 'kinda': 1345, 'king': 1346, 'knight': 1347, 'knowing': 1348, 'koi': 1349, 'kolkata': 1350, 'kota': 1351, 'l': 1352, 'lal': 1353, 'lgbtq': 1354, 'liar': 1355, 'light': 1356, 'log': 1357, 'lovers': 1358, 'ltq': 1359, 'maa': 1360, 'madness': 1361, 'mahatma': 1362, 'mai': 1363, 'main': 1364, 'makers': 1365, 'mangal': 1366, 'mard': 1367, 'mart': 1368, 'masala': 1369, 'masses': 1370, 'master': 1371, 'matata': 1372, 'meaningful': 1373, 'mentioned': 1374, 'menus': 1375, 'minister': 1376, 'ministry': 1377, 'mirza': 1378, 'misogynistic': 1379, 'moment': 1380, 'morality': 1381, 'motive': 1382, 'movement': 1383, 'much': 1384, 'mute': 1385, 'mutual': 1386, 'names': 1387, 'nationalism': 1388, 'naval': 1389, 'nazi': 1390, 'negativity': 1391, 'nic': 1392, 'nicely': 1393, 'nil': 1394, 'nobody': 1395, 'note': 1396, 'nowadays': 1397, 'object': 1398, 'original': 1399, 'over': 1400, 'papal': 1401, 'park': 1402, 'pass': 1403, 'passionate': 1404, 'past': 1405, 'patriarchy': 1406, 'period': 1407, 'platform': 1408, 'plays': 1409, 'popular': 1410, 'porn': 1411, 'portrayed': 1412, 'post': 1413, 'practical': 1414, 'praising': 1415, 'prem': 1416, 'presented': 1417, 'press': 1418, 'previous': 1419, 'prime': 1420, 'probably': 1421, 'profession': 1422, 'properly': 1423, 'property': 1424, 'provoke': 1425, 'rage': 1426, 'rahul': 1427, 'raise': 1428, 'rajasthan': 1429, 'ramadhan': 1430, 'ramadhir': 1431, 'raoul': 1432, 'rated': 1433, 'recent': 1434, 'red': 1435, 'relation': 1436, 'relationships': 1437, 'republic': 1438, 'result': 1439, 'romantic': 1440, 'romeo': 1441, 'royal': 1442, 'sake': 1443, 'sam': 1444, 'sanga': 1445, 'sarah': 1446, 'saving': 1447, 'science': 1448, 'security': 1449, 'sedition': 1450, 'seek': 1451, 'seems': 1452, 'sells': 1453, 'sen': 1454, 'senseless': 1455, 'services': 1456, 'sexy': 1457, 'shades': 1458, 'shoot': 1459, 'should': 1460, 'shout': 1461, 'six': 1462, 'slave': 1463, 'smoker': 1464, 'smoking': 1465, 'soft': 1466, 'sold': 1467, 'soon': 1468, 'spirit': 1469, 'spoil': 1470, 'squad': 1471, 'sri': 1472, 'standards': 1473, 'star': 1474, 'statement': 1475, 'statements': 1476, 'storyline': 1477, 'strange': 1478, 'strong': 1479, 'style': 1480, 'subscriber': 1481, 'subtitles': 1482, 'success': 1483, 'suffering': 1484, 'supposed': 1485, 'swara': 1486, 'target': 1487, 'tells': 1488, 'terror': 1489, 'theatre': 1490, 'therapy': 1491, 'thora': 1492, 'thrown': 1493, 'tight': 1494, 'todays': 1495, 'traitors': 1496, 'transcended': 1497, 'treat': 1498, 'treating': 1499, 'trending': 1500, 'trust': 1501, 'tube': 1502, 'turn': 1503, 'understands': 1504, 'unrealistic': 1505, 'uri': 1506, 'us': 1507, 'useless': 1508, 'vanga': 1509, 'vaun': 1510, 'victimhood': 1511, 'vile': 1512, 'villain': 1513, 'wacko': 1514, 'wait': 1515, 'wali': 1516, 'wall': 1517, 'wasseypur': 1518, 'wat': 1519, 'wen': 1520, 'were': 1521, 'womanizer': 1522, 'worked': 1523, 'working': 1524, 'would': 1525, 'writing': 1526, 'xxx': 1527, 'xyz': 1528, 'yas': 1529, 'youngsters': 1530, 'zindabad': 1531, 'ि': 1532, 'ই': 1533, 'ে': 1534, \"'d\": 1535, '20': 1536, '2019': 1537, '910': 1538, 'a4': 1539, 'accusations': 1540, 'achieve': 1541, 'activist': 1542, 'activity': 1543, 'addicted': 1544, 'addiction': 1545, 'admire': 1546, 'advice': 1547, 'afraid': 1548, 'ali': 1549, 'allegations': 1550, 'alpha': 1551, 'american': 1552, 'analyze': 1553, 'angle': 1554, 'animal': 1555, 'anna': 1556, 'anurag': 1557, 'anything': 1558, 'approach': 1559, 'article': 1560, 'asia': 1561, 'ask': 1562, 'aspects': 1563, 'assholes': 1564, 'attracted': 1565, 'attractive': 1566, 'aura': 1567, 'authorities': 1568, 'average': 1569, 'awaiting': 1570, 'band': 1571, 'bangladeshi': 1572, 'bar': 1573, 'barat': 1574, 'bashed': 1575, 'be': 1576, 'beating': 1577, 'beautifully': 1578, 'bec': 1579, 'become': 1580, 'been': 1581, 'beginning': 1582, 'begins': 1583, 'behalf': 1584, 'bengali': 1585, 'bet': 1586, 'beta': 1587, 'bhakts': 1588, 'biased': 1589, 'bitter': 1590, 'blame': 1591, 'blaming': 1592, 'blow': 1593, 'boats': 1594, 'boring': 1595, 'both': 1596, 'botha': 1597, 'boyfriend': 1598, 'brains': 1599, 'breaking': 1600, 'bright': 1601, 'bringing': 1602, 'brothers': 1603, 'cab': 1604, 'careful': 1605, 'cash': 1606, 'cause': 1607, 'celebrated': 1608, 'charged': 1609, 'chasing': 1610, 'cheering': 1611, 'choose': 1612, 'chores': 1613, 'choudhury': 1614, 'chu': 1615, 'citizen': 1616, 'civil': 1617, 'clever': 1618, 'comfortable': 1619, 'commercial': 1620, 'commitment': 1621, 'compassion': 1622, 'concerned': 1623, 'condemn': 1624, 'condition': 1625, 'context': 1626, 'contributed': 1627, 'controversy': 1628, 'couple': 1629, 'couples': 1630, 'cousin': 1631, 'creating': 1632, 'creator': 1633, 'critically': 1634, 'criticism': 1635, 'cult': 1636, 'cup': 1637, 'd': 1638, 'dad': 1639, 'daily': 1640, 'dala': 1641, 'dance': 1642, 'dard': 1643, 'daring': 1644, 'darkness': 1645, 'debating': 1646, 'decade': 1647, 'decisions': 1648, 'deeply': 1649, 'defending': 1650, 'demons': 1651, 'deported': 1652, 'depressed': 1653, 'depth': 1654, 'deserved': 1655, 'destroy': 1656, 'details': 1657, 'dictionary': 1658, 'discussion': 1659, 'disgrace': 1660, 'disturb': 1661, 'dominant': 1662, 'dominating': 1663, 'donate': 1664, 'done': 1665, 'doubt': 1666, 'downfall': 1667, 'duration': 1668, 'duty': 1669, 'e': 1670, 'early': 1671, 'easy': 1672, 'effect': 1673, 'effects': 1674, 'efforts': 1675, 'election': 1676, 'else': 1677, 'elses': 1678, 'empowerment': 1679, 'engaged': 1680, 'enjoyed': 1681, 'episode': 1682, 'escape': 1683, 'eunuch': 1684, 'exaggerated': 1685, 'exercise': 1686, 'exposing': 1687, 'express': 1688, 'extreme': 1689, 'fame': 1690, 'fast': 1691, 'faults': 1692, 'females': 1693, 'fiance': 1694, 'fictional': 1695, 'field': 1696, 'fill': 1697, 'fine': 1698, 'flaws': 1699, 'force': 1700, 'forcefully': 1701, 'four': 1702, 'friendship': 1703, 'fringe': 1704, 'fucks': 1705, 'funds': 1706, 'gali': 1707, 'gem': 1708, 'general': 1709, 'genuinely': 1710, 'gods': 1711, 'goes': 1712, 'goole': 1713, 'granted': 1714, 'groups': 1715, 'guilty': 1716, 'gulf': 1717, 'gully': 1718, 'gulo': 1719, 'harass': 1720, 'haryana': 1721, 'hasan': 1722, 'hating': 1723, 'heavy': 1724, 'helped': 1725, 'hi': 1726, 'highly': 1727, 'hindustan': 1728, 'ho': 1729, 'hup': 1730, 'hypocrites': 1731, 'idolized': 1732, 'iii': 1733, 'immediate': 1734, 'impose': 1735, 'incidents': 1736, 'individuals': 1737, 'indulge': 1738, 'infection': 1739, 'instigate': 1740, 'instigated': 1741, 'instigating': 1742, 'insult': 1743, 'intense': 1744, 'interstellar': 1745, 'intrest': 1746, 'involved': 1747, 'jailed': 1748, 'jesus': 1749, 'jobs': 1750, 'journey': 1751, 'kalkara': 1752, 'kedarnath': 1753, 'keeping': 1754, 'kgb': 1755, 'kgf': 1756, 'kill': 1757, 'kindly': 1758, 'kissed': 1759, 'kohl': 1760, 'kotha': 1761, 'kudos': 1762, 'kutiya': 1763, 'kutti': 1764, 'last': 1765, 'laura': 1766, 'leader': 1767, 'leaves': 1768, 'leaving': 1769, 'less': 1770, 'license': 1771, 'lied': 1772, 'lifestyle': 1773, 'logo': 1774, 'lok': 1775, 'looks': 1776, 'looser': 1777, 'low': 1778, 'loyal': 1779, 'lryevxeva': 1780, 'lying': 1781, 'machu': 1782, 'majority': 1783, 'males': 1784, 'management': 1785, 'manner': 1786, 'mans': 1787, 'manual': 1788, 'many': 1789, 'mao': 1790, 'marriages': 1791, 'mask': 1792, 'massagboy': 1793, 'matters': 1794, 'medico': 1795, 'mediocre': 1796, 'meets': 1797, 'member': 1798, 'mentality': 1799, 'mention': 1800, 'middle': 1801, 'military': 1802, 'million': 1803, 'mine': 1804, 'mins': 1805, 'minute': 1806, 'mirror': 1807, 'mistake': 1808, 'mm': 1809, 'mondol': 1810, 'month': 1811, 'morally': 1812, 'morals': 1813, 'moves': 1814, 'mud': 1815, 'mumbai': 1816, 'murder': 1817, 'music': 1818, 'n3d5ilngama': 1819, 'narratives': 1820, 'narrow': 1821, 'ncc': 1822, 'next': 1823, 'nine': 1824, 'obnoxious': 1825, 'obsessed': 1826, 'obsession': 1827, 'offensive': 1828, 'on': 1829, 'opener': 1830, 'opening': 1831, 'opportunity': 1832, 'orbit': 1833, 'ord': 1834, 'otherwise': 1835, 'out': 1836, 'pair': 1837, 'par': 1838, 'parliament': 1839, 'party': 1840, 'patriarchal': 1841, 'paul': 1842, 'phase': 1843, 'phone': 1844, 'photon': 1845, 'pig': 1846, 'plot': 1847, 'porimoni': 1848, 'potray': 1849, 'practice': 1850, 'praised': 1851, 'pratley': 1852, 'pregnant': 1853, 'pressure': 1854, 'priority': 1855, 'problematic': 1856, 'producers': 1857, 'projects': 1858, 'pros': 1859, 'prosecuted': 1860, 'psychological': 1861, 'pyar': 1862, 'q': 1863, 'questions': 1864, 'quick': 1865, 'race': 1866, 'radhe': 1867, 'rajeev': 1868, 'rajesh': 1869, 'rajiv': 1870, 'rather': 1871, 'reactions': 1872, 'realise': 1873, 'redemption': 1874, 'regressive': 1875, 'relating': 1876, 'release': 1877, 'relevant': 1878, 'remain': 1879, 'remove': 1880, 'replicate': 1881, 'report': 1882, 'research': 1883, 'respectable': 1884, 'respected': 1885, 'response': 1886, 'responsibilities': 1887, 'reviewing': 1888, 'ridiculous': 1889, 'rise': 1890, 'roles': 1891, 'rooted': 1892, 'rotten': 1893, 'ruined': 1894, 'rules': 1895, 'running': 1896, 'saal': 1897, 'sahara': 1898, 'sarcastic': 1899, 'saved': 1900, 'says': 1901, 'scared': 1902, 'script': 1903, 'selective': 1904, 'set': 1905, 'sexism': 1906, 'sexually': 1907, 'sh': 1908, 'shameful': 1909, 'sheds': 1910, 'shirts': 1911, 'shocked': 1912, 'similar': 1913, 'sin': 1914, 'singles': 1915, 'sisters': 1916, 'sites': 1917, 'sitting': 1918, 'skills': 1919, 'sleep': 1920, 'sleeping': 1921, 'small': 1922, 'solely': 1923, 'son': 1924, 'sonar': 1925, 'source': 1926, 'special': 1927, 'specialist': 1928, 'specifically': 1929, 'spoilers': 1930, 'spoken': 1931, 'spotted': 1932, 'stage': 1933, 'stating': 1934, 'station': 1935, 'stick': 1936, 'strongly': 1937, 'studied': 1938, 'studies': 1939, 'stunt': 1940, 'subjected': 1941, 'subscribe': 1942, 'substance': 1943, 'sucked': 1944, 'supporter': 1945, 'supports': 1946, 'surgery': 1947, 'suu': 1948, 'sweet': 1949, 'teacher': 1950, 'technology': 1951, 'terrible': 1952, 'terrorist': 1953, 'th': 1954, 'than': 1955, 'thanked': 1956, 'theatres': 1957, 'thier': 1958, 'thousands': 1959, 'threatening': 1960, 'tht': 1961, 'tiara': 1962, 'toilet': 1963, 'tolerate': 1964, 'tom': 1965, 'treated': 1966, 'treats': 1967, 'truly': 1968, 'tutti': 1969, 'two': 1970, 'types': 1971, 'ultimate': 1972, 'ultra': 1973, 'uncomfortable': 1974, 'understood': 1975, 'uneducated': 1976, 'unlike': 1977, 'unnecessary': 1978, 'upcoming': 1979, 'usher': 1980, 'victims': 1981, 'viewer': 1982, 'villa': 1983, 'villan': 1984, 'vulgar': 1985, 'walk': 1986, 'wasted': 1987, 'wasting': 1988, 'ways': 1989, 'weak': 1990, 'wear': 1991, 'web': 1992, 'webster': 1993, 'weird': 1994, 'wichita': 1995, 'wid': 1996, 'witch': 1997, 'writer': 1998, 'writers': 1999, 'wrote': 2000, 'yellow': 2001, 'youths': 2002, 'zaid': 2003, 'ल': 2004, 'ট': 2005, 'ন': 2006, 'ভ': 2007, '🤘': 2008, '\\U0001f91f': 2009, '🤠': 2010, '\\U0001f970': 2011})\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data,min_freq=3, vectors = vectors)  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(\"Size of topic vocab:\",len(TEXT.vocab))\n",
    "print(\"Size of label vocab:\",len(LABEL.vocab))\n",
    "print(TEXT.vocab.freqs.most_common(11))  \n",
    "print(LABEL.vocab.freqs.most_common(14))\n",
    "print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanshgrover/anaconda3/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "b_sz = 128\n",
    "\n",
    "train_loader, val_loader = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size = b_sz,\n",
    "    sort_key = lambda x: len(x.Text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim = 12, n_layers = 2, bidir = True, dropout = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidir,\n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        dense_outputs=self.dense(hidden)\n",
    "        outputs=self.softmax(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = labels\n",
    "dropout = 0.2\n",
    "\n",
    "model_ = model(vocab_size, embedding_dim, num_hidden_nodes, num_output_nodes, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (embedding): Embedding(2012, 300)\n",
      "  (lstm): LSTM(300, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (dense): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "The model has 714,387 trainable parameters\n",
      "torch.Size([2012, 300])\n"
     ]
    }
   ],
   "source": [
    "print(model_)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model_):,} trainable parameters')\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model_.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(preds, y):\n",
    "    counts = 0\n",
    "    for i in range(preds.shape[0]):\n",
    "      counts += (torch.max(preds[i], 0)[1] == y[i]).float()\n",
    "      \n",
    "    return counts/preds.shape[0]\n",
    "    \n",
    "model_ = model_.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text, text_lengths = batch.Text\n",
    "        label = batch.label\n",
    "\n",
    "        text = text.to(device)\n",
    "        label = label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        predictions = model(text, text_lengths).squeeze()\n",
    "\n",
    "        try:\n",
    "              loss = criterion(predictions, label)\n",
    "              acc = accuracy(predictions, label)\n",
    "        except:\n",
    "              continue\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / (len(iterator)-1), epoch_acc / (len(iterator)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            text, text_lengths = batch.Text\n",
    "            label = batch.label\n",
    "\n",
    "            text = text.to(device)\n",
    "            label = label.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            \n",
    "            try:\n",
    "                  loss = criterion(predictions, label)\n",
    "                  acc = accuracy(predictions, label)\n",
    "            except:\n",
    "                  continue\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / (len(iterator)-1), epoch_acc / (len(iterator)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanshgrover/anaconda3/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/ramanshgrover/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a55186d25eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-94a0cf9b2950>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9577b7a28516>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_lengths)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpacked_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    train_loss, train_acc = train(model_, train_loader, optimizer, criterion)\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model_, val_loader, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "      optimizer.zero_grad()   \n",
    "      \n",
    "      text, text_lengths = batch.Text   \n",
    "      \n",
    "      predictions = model_(text, text_lengths).squeeze()\n",
    "      loss = criterion(predictions, batch.label.type(torch.LongTensor))\n",
    "      \n",
    "      loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchnlp\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>B</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>normalized lexicon</th>\n",
       "      <th>monolingual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>next part</td>\n",
       "      <td>['next', 'part']</td>\n",
       "      <td>['next', 'part']</td>\n",
       "      <td>next part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>iii8mllllllm mdxfvb8o90lplppi0005</td>\n",
       "      <td>['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']</td>\n",
       "      <td>['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']</td>\n",
       "      <td>iii 8mllllllm mdxfvb 8o90lplppi0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>osm vedio make vedios</td>\n",
       "      <td>['osm', 'vedio', 'make', 'vedios']</td>\n",
       "      <td>['osm', 'osf', 'vedic', 'make', 'videos']</td>\n",
       "      <td>osm osf vedic make videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>what fuck this? respect shwetabh watching vide...</td>\n",
       "      <td>['what', 'fuck', 'this', '?', 'respect', 'shwe...</td>\n",
       "      <td>['what', 'fuck', 'fuck', 'this', '?', 'respect...</td>\n",
       "      <td>what fuck fuck this ? respect respect whitish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>concerned authorities bring arundathi roy type...</td>\n",
       "      <td>['concerned', 'authorities', 'bring', 'arundat...</td>\n",
       "      <td>['concerned', 'authorities', 'bring', 'arundat...</td>\n",
       "      <td>concerned authorities bring arundathi roy roy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ID                                               Text  \\\n",
       "0           0  C45.451                                          Next part   \n",
       "1           1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005   \n",
       "2           2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...   \n",
       "3           3  C4.1961  What the fuck was this? I respect shwetabh and...   \n",
       "4           4  C10.153  Concerned authorities should bring arundathi R...   \n",
       "\n",
       "  label     B                                              clean  \\\n",
       "0   NAG  NGEN                                          next part   \n",
       "1   NAG  NGEN                  iii8mllllllm mdxfvb8o90lplppi0005   \n",
       "2   NAG  NGEN                              osm vedio make vedios   \n",
       "3   NAG  NGEN  what fuck this? respect shwetabh watching vide...   \n",
       "4   NAG  NGEN  concerned authorities bring arundathi roy type...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                   ['next', 'part']   \n",
       "1   ['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']   \n",
       "2                 ['osm', 'vedio', 'make', 'vedios']   \n",
       "3  ['what', 'fuck', 'this', '?', 'respect', 'shwe...   \n",
       "4  ['concerned', 'authorities', 'bring', 'arundat...   \n",
       "\n",
       "                                  normalized lexicon  \\\n",
       "0                                   ['next', 'part']   \n",
       "1   ['iii', '8mllllllm', 'mdxfvb', '8o90lplppi0005']   \n",
       "2          ['osm', 'osf', 'vedic', 'make', 'videos']   \n",
       "3  ['what', 'fuck', 'fuck', 'this', '?', 'respect...   \n",
       "4  ['concerned', 'authorities', 'bring', 'arundat...   \n",
       "\n",
       "                                         monolingual  \n",
       "0                                          next part  \n",
       "1                iii 8mllllllm mdxfvb 8o90lplppi0005  \n",
       "2                          osm osf vedic make videos  \n",
       "3  what fuck fuck this ? respect respect whitish ...  \n",
       "4  concerned authorities bring arundathi roy roy ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    z = np.zeros(12, dtype = int)\n",
    "    z[x-1] = 1\n",
    "    return tuple(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, label = 'label', text = 'Text', drop = ['Unnamed: 0', 'ID','monolingual','B','clean','tokenized','normalized lexicon'], train = False):\n",
    "    df_s = df\n",
    "    df_s['text'] = ''\n",
    "    for sent in df[text]:\n",
    "        df_s['text'] += sent\n",
    "        df_s['text'] += \" \"\n",
    "    df_s['labels'] = pd.Series(encoder.batch_encode(list(df[label]))).apply(func)\n",
    "    df_s = df_s.drop(drop, 'columns')\n",
    "    train_df, eval_df = train_test_split(df_s, test_size=0.2)\n",
    "\n",
    "    if(train):\n",
    "        return train_df, eval_df\n",
    "    else:\n",
    "        return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, eval_df = prepare_data(df, label = 'label', text = 'Text', train=True) # Takes considerable amount of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_df = eval_df.reset_index()\n",
    "# train_df = train_df.reset_index()\n",
    "# eval_df = eval_df.drop('index', 'columns')\n",
    "# train_df = train_df.drop('index', 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_excel('train_df.xlsx', index=False)\n",
    "# eval_df.to_excel('eval_df.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"train_df.xlsx\")\n",
    "eval_df = pd.read_excel(\"eval_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Next part Iii8mllllllm\\nMdxfvb8o90lplppi0005 🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more vedios like this What the fuck was this? I respect shwetabh and i have been watching his videos\\nfor quite a long time but this review was shit. Nobody wants to watch the\\nmovie for reality or blah. You dont watch movies for inspiration you would\\nrather read books and biographies. Yes its true that some people are getting\\ninfluenced and doing all shitty fuckery but just think. Anyone who takes this\\nmovie seriouslyis already a chutiya. And you dont go to theatre in india for\\nsome reality shit and if u really seek reality and logical scripts and\\ncharacters without plotholes and all then you wouldnt be watching kabir singh.\\nSo I think you just made this for views,  \\ncause theres no need for this so called raw review. And one thing you acted\\nlike u forgot the movie name like seriously you know the whole story and you\\npronounced this overhyped mess wrongly? Oh common!!!😂 Concerned authorities should bring arundathi Roy and other these type of\\npeople before the law of the land.for giving anti national statements It seems like these people want to be famous nothing more they don\\'t care if\\npeople die by their hateful talks. Best topic for Law Students ! Even when kabir singh was unaware that Preeti is having his son he was ready\\nto accept other\\'s baby and was ready to give his name though that was his baby\\nbut still he was ready to accept preeti even after thinking she has sex with\\nother guy and feminists would not see this. She is wrong . 6001733614 Hindi old muvi rait Very well said dude, totally agree. @Dushant Sain EXACTLY!!!!! don\\'t we just go to see a movie to comprehend what\\nthe director and the story telling has to offer.... it\\'s about understanding\\nthe Movie not Making all the things shown in the movie to the heart. Our Role Model - Shwetabh > Kabir ❤️ @usher luck well i am from haryana. A small city called hisar. You can give me\\nyour number if u want but frankly i will not give you mine. I would like you\\nas a friend. If you would like we can chat on facebook though she best arbitrator in kamatipura & sonargachi area settlements Yeah man **Fuck Bollywood** and become **mature** in real life! It Calls Uneducated Person means Unexpected Behavior 🤣😂🤣😂..\\nThoko like Sahi kaha 😂🤣  \\nLogic level ---- Bollywood its not good i think its all dimaghi keeda being a gay or lesbian.. giving the movie review of super 30? Saurabh Dwivedi sir, i appreciate you for maintaining neutral view of point.\\nAs for now, we have two media one modi loving and 2nd is modi hating. But you\\nare neutral Why can\\'t the Indian government take serious actions to those who talk against\\nthe nation or anyone who involved in instigating any sort of violence or\\ndisturbing the peace of the nation. Freedom of speech doesn\\'t allow anyone to\\ngo anti-national. This bitch (Arundhati Roy) has already given such statements\\nthat are anti-national on numerous occasions but she is still living freely.\\nIt\\'s high time for the government to pass a law against these bastards, it\\ndoesn\\'t matter who you are. Exactly. That was 100000000000x better than shitty kabir singh. Chhichhore review @mohammad ismail xc feminism means equality not discrimination first you should learn about this\\ngo and study about feminism. Like Baahubali. will blockbuster Kabir singh..  \\nYes : Like  \\nNo : Comment  \\n  \\nall the best shahid ji😍👇👇  \\nFrom Rebal star prabhas Fans Full support 💪🙌 bro  \\nKeep it up 👍 I literally cannot imagine a scenario where I\\'d be watching content from this\\nchannel, leave alone penning down a comment. I personally abhor this\\npropaganda infused right-wing program and have reported it multiple times.\\nIt\\'s in the best interest of the nation if it ceases to exist from the digital\\nplatforms and is confined to television only. Nevertheless, needed to get\\ncertain thoughts off of my chest so here goes:  \\n1\\\\. Stop broadcasting these staged debates that resemble poorly produced\\nb-grade flicks at best. The background score during the intro, the\\nparticipants who are more like the bickering neighborhood aunties than\\ndignified panelists, etc. stink of sub-standard nonsense. Stop fooling the\\npublic.  \\n2\\\\. Instead of all this nonsense, why the hell can\\'t you show how the PM and\\nHome Minister have successfully confused the nation and are literally behaving\\nlike clueless self-contradicting juveniles?  \\n3\\\\. With a few days left for 2020, our nation is yet to overcome the confines\\nof religion. I had high hopes for my country and had started believing that we\\nwould achieve great heights in the field of Science and Technology that would\\nput us in the big leagues, but no, we are all weighed down by this archaic\\nconcept (read religion) and have ensured that progress is a goal that is quite\\nfar from our reaches.  \\nA note to Republic TV:  \\nInstead of showing all this nonsense about anti-nationals, lutyens and what\\nnot please focus on key items that are deterring our nation (unemployment,\\npoor economy,etc.). The mass does not care about the sub-standard reporting\\nyou do on these ridiculous theories. They want some concrete information that\\nthe news channels alone can provide. I was waiting for it.... Very honest opinion OMG 😱 Llovu You are Right broo thanks she is castigating our citizens to direspect our country and its law .who\\ndonkys gave her Booker prize .she is mocking and insulting our country and\\nbehaving like wicked and crafty woolf . shame on you .you wampnthi . q\\nchutyapnti kar rahi ho . jai hnind .jay jagat . Watch this amazing video\\n[https://www.youtube.com/watch?v=S6g_W2nTcvQ&app=desktop](https://www.youtube.com/watch?v=S6g_W2nTcvQ&app=desktop) hats off brother Too much spoiler 🙄🙄🙄 Change Title 😒😒 but can you catch them, no....if yes fial complian agaist them in court and\\npunish then and put them in jail..but you cant//this is the fact...she is the\\ndanderous lady and you are helpless..court are reluktunt to punish them By the way i myself being a 21st century modern girl, i did not watch four\\nmore shots as i found the trailer and the interviews of the cast very\\ndisturbing. Feminism is losing it’s real agenda i.e equality of gender, but\\nbecoming an advocate of all sort of sexual shit. Feminism is much more than\\nsexual freedom, i request all my fellow girls to not get carried away by such\\nideas. Ranu is a bad girl 👍👍😸😆😂 Looks like a ghost, real conjuring The world needs more men like you **Correct** @Pratik Borade just saw 2 mins of the video you recommend and seems like you\\nwrite your own dictionary. Sorry but I would be following other dictionaries\\nlike Cambridge and merriam webster. The whole Bollywood premise is showing a life people dream about and not\\nrealism. It\\'s a form of escapism from reality. Salute to you sir,great thinking Watch this song..Awesome\\n<https://youtu.be/4Ax1099ML-Q> Very very nice Bor Very nice video Epic movie I had head ache during this movie and also post movie.. I simply hated the\\nmovie , completely disagreed and indigestible plot... & people were like how\\ncan u dislike the movie.. whereas I\\'m shocked what is there to be liked except\\nthe songs... Super bro Good job,,plz sub Weren\\'t you a liberal yourself?😂 That is why I like amir khan Best film for sahid Kapoor If you are a man then you are a fool of india..now women are fighting for\\nmen...do you know that? This mentally ill Lady is a barking Street dog whose intentions to pull\\npeople\\'s attention that she is alive Ram Raja - she is a female dog - who can’t even keep a husband - married and\\nseparated twice because she likes to sleep around Manjee.. Chakshu ji.. Nd.. Akhil ji... 😁 😂 🤣 🤣 🤣 fab.. 😁 😂 🤣 Totally agree with ur points bro nd kabir singh haters must have girts to\\ncounter these points if they can\\'t then they must shut their fuckin mouths\\nrather than vomiting diarrhoea against d movie.....if they doesn\\'t want to\\nwatch d movie then who is forcing them....... All of you r jealous of Ranu Mondal. .you have no education. .bt we support\\nRanu ji fr her talent ...we never interfare her personal issues. .we love her\\ndevine voice. .dats it.. hi pratik, hope you are doing well. Call it a coincidence or anything, I came\\nacross a designer liberal page criticising Kabir Singh for MISOGYNY. Frankly\\nspeaking I have seen only Arjun Reddy, and I was unable to find single trace\\nof misogyny anywhere. If these people were so concerned about women, there\\nwill call out real tharkis in our country. But anyway they like Veere Di\\nWedding and 4 More shots please. So better neglect them and let them whine\\nlike babies. Loved the couple Arjun and Deepthi, Kabir and Priti👩\\u200d❤️\\u200d👨👩\\u200d❤️\\u200d👨.\\nMovie is top class. Keep up the good work 🙏😇 Kabir singh one of the best love story. Dil se jud gayi movie Shadaa by Diljit Dosanjh  \\nReview  \\nPlease 🙏 🙏 col You are talking real sense bro.. One word for u bhaad me jaa chudail Wow...pratik sir u r analysis really superb...hope more people like u exists\\nin bollywood critics...fk those paid critics nd pseudo femmies nd commies.... Mensutra is the leader of youth....Thnx for your contribution to our Indian\\nSociety Arundhati Roy has biggest bowls ,,,,,,, Love from bd💖💖🇧🇩 hlooo @Babu Lal good morning ji Please do a fan meetup! We want to meet you in person. There are many\\ncommunity centres in and near Saket that you can book for same. awesome movie.. how can u talk for so much time and u looking just at the camera.. which means\\nit\\'s like talking to yourself.. Finally, i can legally call indians gay Really Totally agree👍 As per Arundhati she should give her name as Kung Fu Kutiya and she should\\nkeep practicing balancing tooth brushes on her nipples (god of small things),\\nthat is all she is worth for. They (Roy, Kavita Krishnan, Shehla Rashid)\\nshould rent apartments in Hira Mandi). Ayushmann khurana nawazuddin siddique rajkumar Rao are really good actors 8617618488 Ya gay person never like girls....but they won\\'t going into violence against\\ngirls...ur approach is entirely wrong man😒😒😒👎👎👎 No means no... Awesome sarcasm... తమ్ముడు వైపర్ ఏంది నీ బాధ... 🤔  \\nగమున్నుండవాయ్...  \\nరిప్లై ఇవ్వలేదని ఓ కామెంట్స్ పెట్టుకుంటూపోతున్నారు  \\nShahid he is good actor & better then khan\\'s So we are all just encourage  \\n  \\nDon\\'t negative be positive  \\nPrabhas & shahid one of the greatest friends So I\\'m just supporting  \\n  \\nI\\'m member of prabhas fans association  \\n  \\nEagerly waiting For shad\\'s oF saaho  \\n  \\nJust waiting all I think you are one of the most honest youtubers on the platform. Respect! 🙏 All hutiyas one side and swetabh one side. amezing brother🤘 Give the fake name and fake details and you will end up being unable to vote,\\nnor open bank account nor apply for any social benefits... কামরুন নাহার right to moto chele a rakom ma der chere dei tar pare ninda kare\\ni heat you . Nice msg in end. Awesome video 👍👍👍👍👌👌💗💗 Yes I saw in reality how protective lesbian girl is when it comes to her\\ngirlfriend..... Salute to that girls...lgbt rocks Good.. :) Iam a medical student and we give atleast 6-7 hrs for subjects . There is\\nnothing like personal life in medical field. For the sake of patients you have\\nto sacrifice your personal life. She is a drug adict n dinner girl of billionaire these mental congress paid leftist so call intellectuals thinking Hindustan is\\na jock.. these group will be behind bar or will be eliminated before\\n2023...just wait...this govt will not spare Kabir singh 2019 most overrated movie🤮🤮 Hit like if you love ayushmann khurana @Sayan Bose Thanks.. Respect. Have u watched 3idiots, OMG, queen, Parmanu, Bajrangi Bhaijaan, Sultan,\\nDangal, Padman etc?????? Better try to watch these good movies and remove ur\\nnegativity about bollywood. Right 👌 bro Best and well studied review bro...👍 Totally agree......bro..Specially for Army and for country security... Al9\\n\\n\\n,Alicia Who is watching this after india beat afganistan in world cup 2019. Extremely sad, very very tragic. I hat ranu Mondal Sucharita tyagi is awesome Sucharita tyagi is chutiya critic. At [14:27](https://www.youtube.com/watch?v=J2J5ssSP5yQ&t=14m27s) ...this is\\nWhat i said to my Father after 12th 😂😂😂😂😂😂😂 Homosexuality is ban Pseudo liberals are themselves too much intolerant good job done by this man Your voice is very sweet Ya he is the only who talks sense on you tube +Naughty World hiii It\\'s good video but not good to murder of female <https://www.bbc.com/marathi/india-49022841> This movie is really great I saw arjun reddy.... i am not a liberal or a feminist but it is my opinion I\\nsaw arjun reddy yesterday on amazon and for one i had to pause whenever\\ncharacter speak bcoz d subtitles were too fast i didnt have time to read the\\nwhole thing.  \\nSecondly i didnt like arjun ka character- womZaniser, drug addict,\\nalcoholic.and very abusive.  \\nThirdly, by saying i like thia girl in particular clothing and then going from\\nclass to class plus the girl\\'s hostel and giving it the name of love isn\\'t\\nlove at all and it\\'s CREEPY like srk chasing after kajol in DDLJ.  \\nFourth point, after repeated pleas by his parents, he still drinks and smokes.  \\nHe was shown in a negative light....but atleast there was a courtroom scene.  \\nAnd he is proud to say that while he was high none of his patients died?\\nSeriously?  \\nHe slapped a girl when it wasnt expected at all. He was very regressive. Not\\nonly regressive but spoilt, unapoligetoc and obnoxious.  \\nOne time watch but yet inspite all this i could see the effort made by the\\nmakers.  \\nGOOD EFFORT... I DIDNT SAY GREAT FILM. THERE WASNT ANYTHING GREAT ABOUT THE\\nFILM. ARJUN REDDY WAS as my teacher would say A SPINELESS JELLYFISH. Bro, Nice video You are alright This lady from BJP is crazy this is how u react man such a foolish and\\nignorant lady I just love how two women shout over each other about another women. Feminists\\u200b & Liberals are curse to humanity I hate these faminisim.....they don\\'t know even the meaning of it ....and\\ncalled themselves feminist....real woman don\\'t care of them... All the libtard reviews are like...  \\n  \\n\"No woman should watch the movie\"  \\n\"No one should like the movie\"  \\n\"If anyone likes the movie they are a terrible person\" 🤦  \\n  \\nEven if they are not outrightly saying those statements that is exactly what\\nthey are implying...  \\n  \\nThey don\\'t care about the 10s of thousands of women who come out of the\\ntheaters saying they loved the movie...🤷 Because they are wrong and only the\\nliberal feminist point of view is the absolute truth...🤮 Toy Story 4 review sir please Super 🤠🤠🤠 @jacky ju IF YOU WILL TAKE 5 ML TESTOSTERONE HORMONE INJECTION AND NOT FIND A\\nFEMALE YOU CAN EVEN FUCK A DOG GaNgss Of wassepur Fanss Hit A like....😂😂😂 I totally agree with you sir 💯 Salute bro bro....😂😂😂just try and replace the girl with ur sister or anyone close to\\nya.. You got a subscriber 👍 Sir I Have Sent A Personal Message To You on Instagram .... Please Make a\\nVideo on it Arundati has to go to Bangladesh..... And we have to change her name to\\nkutta.... 💐💐💐💐 Gay are not criminals, its a sexual identity, please stop sending wrong\\nmessages Wow that\\'s cool bcz i love all lesbians & gays. They are more spacial than uh\\nin my opinion. So i support them cz i respect them ❤❤. Bt i m nt a lesbian This is the failure of the Judicial system, they should make laws to punish\\nwomen who misuse this law. @Be Positive What is your opinion about Muslims not allowing women to enter\\nMasjids ? Why are there no feminists protesting for that ? Superb nice movie I died at Shahid Khan , Kabir Khan 😂😂😂 I guess it\\'s the first film where every reviewer on youtube had a different\\nopinions and views .. woh!  \\nbut I just loved the film!! Now arundhati roy destroyed herself There is no action taken against woman, who file false 498a cases, so crime is\\nthe only option left for a sensible Men like him, who was looking for\\njustice... Bad boy character is more preferable then good character in girls eye...that\\'s\\nwhy destructive films popular... Well I do agree with most of the points you said..but I just feel that the\\ninitial things done by Kabir in order to approach Priti were kind of scary.\\nNormally any girl would get scared. Priti\\'s reaction to all of that was kind\\nof weird to me. Watch Section 375. It\\'s a masterpiece exposing feminism. Bhai types of girls series continue Karo... Very good video Yes bro you ar right @Franklin Bro. I agree 💯% with u... Shwetabh pin my comment.\\nYou are too good man. se se se it\\'s hearing looking feeling veery bed... If films influence societies then Kabir Singh marks the beginning of a dark\\nsociety Gazabb review .... I thought you would praise this film... Thank God you\\nbashed it.... Love your review Finally, most anticipated video of Shwetabh sir! Sonagachi hit like❤ Encounter................Encounter................Encounter.............. If you have guts then speak against child rapist prophet mohammed I have not seen kabir singh yet bt have seen Arjun Reddy. Grt movie. U r very\\nmuch right to point out the hypocrisy of the liberals and so called\\nfeminists.Actually they themselves r confused of what they want in life and as\\na result of this they live a lonely life at the end of the day. They don\\'t\\nwant to understand relationship. Their feminism starts with the f... word and\\nends in the f...... word. nice bhai Expected some what like the level of Wassepur.. Disappointed.. And yeah\\ndon\\'t... Bring in the anti feminist or cult kinda thing.. Just put your\\nview... Self destruction is a good thing.....be it substance abuse.. A\\n\"thing\".. Or a lifeless soul.. Shut your mouth and start respecting your\\nmother.. In fact u need your parents help 200 crores club movie hai ye 😂 One word for all haters go die somewhere else.. Oooo super Hate this Savdhaan India, Kabir Singh fights back.😁😁 @Pawan Kakade Dude joker sucked. Watch my review and open your damn eyes!! 😂😂amazing practical person Hypocrisy... is a disease Even I watched the movie and I had similar thoughts, but the only appreciable\\npart was Shahid\\'s acting. Nicevedio Hi8 I am a big fan, Pratik Bhai love from the USA 🇺🇸😍 They will know in 2024 Elections when we vote for Modi Government in Majority. Nawazuddin a toxic character babat realistic presentation Right sir ... If anurag kasyab directed this film then it will be like crime petrol show.. 😂 Once again you nailed it!!. Keep going brother. This whore is a member of psuedo intellectual secular gang.She made a villa in\\nnaive ST\\'s land. Frankly I liked only Shahid and his friends acting and their relationship than\\nactual love story. From thumbnail I thought it is carryminati Someone told me ki if you\\'re trying to find out logics you must find it in\\nlife not in films. So watch a movie with just nothing 10000% true 👍👍👍\\nKabir singh is a big chutiya movie Pls review joker...... 1000th like👍 Fuckboy isn\\'t good , but a bully isn\\'t either. Skewed feminism is dangerous\\nand so is toxic masculinity. I totally understand that you have a lot of\\nhatred for liberals n feminists which is justified coz of what a lot of them\\nhave been propogating but not every idea of feminism is wrong pratik.\\nBollywood has a history of showing these things \"cool\", that is my only\\nproblem with these characters. I am all game for negative characters but I\\ndon\\'t like them being glorified, making them look cool. I won\\'t even start\\nwith 4 shots, I didn\\'t even like alia\\'s aggresion in gully boy so it\\'s not one\\nsided. As much as I enjoy your views on nationalism, our history , I didn\\'t\\nfeel comfortable watching this. 🙏 Yes, u r right man Kabir Singh best love story ever 😘😘 As a lesbian, I wouldn\\'t say it\\'ll \"completely\" contribute to reduction in\\npopulation. They need to legalize 2 children policy like China did. Also, all\\ncouples should adopt at least 1 orphan instead of trying to reproduce. Only\\n25% of orphans are being adopted and others will be 18 then kicked out.\\nThey\\'ll become homeless. Rural areas should stop reproducing lots of children. If u need a realistic and grounded love story, watch \\'96\\\\. Vijay setupathy and\\ntrisha. It is a tamil movie. watch it with subs. Hit like for shwetabh gangwar.\\n👇👇 Waste a bullet on Arundathi Roy...she is a traitor Ranu is a bad girl👍👍😸😆😂🤣 Phone sex iam from Odisha state bhubaneswar iam just 24yr old hot and sexy boy\\n09777070288 Who the fuck disliked the video? <https://youtu.be/Jtf5L1h-q9I> My.darling I think chhichore is more realistic. Isiliye to real life ko movie se compare nahi kr skte..... Tue film is amazing...sm. ppl in dis country have problem wid\\neverything...intrstngly these ppl dn hv any problem wid d things that r\\nactually wrong... Arundhati roy is a gr8 writer arnab pl dnt mislead the public Why give importance to her nonsensical utterances? No talks, only arrest her. Love you didi 😁 Immediate arrest her.  \\nwho gave her prize?  \\nredicuous ..... Kabir Singh is dubbing of Arjun Reddy Tollywood industry film directed by the\\nsame guy Sandeep Reddy Vanga and what\\'s so surprising is this movie is biggest\\nblockbuster of Tollywood industry in the respective year. Need more men like\\nyou to get youth\\'s mind into correct direction. Respect for your work man. Tike asa..bro..i like you... I also watch thousands of worldwide movies Korean,Japanese,Hollywood,Taiwan\\nseriously after a decade I will tell you that kabir singh/Arjun reddy is a\\ncult classic movie in india it’s not a simple love story.bro you are awesome\\nyou are telling the real truth.❤️ That\\'s the truth Coming to Delhi to watch your videos bcox net is off in Kashmir You\\'re a true genius!😎😎😎😎😎😎 Harr Londa samajhta hai main Kabir Singh hu, EX: main chain smoker hu like\\nhim, main abusive hu like him, alcoholic hu as usual like him but when it\\ncomes to education, wisdam, carrier non of these even exist for em. Right... NPR will help reaching govt schemes effectively n proprly to minor\\ncommunities. Beautiful @usher luck Fair enough then ... The director\\'s approach isn\\'t very clear to\\nme however , may be it\\'s misinterpreted , may be not . And can\\'t comment on\\nthe movie scenes . Started my comment stating that didn\\'t watch it. Nice review brother love you Make video about Indian series streaming on Netflix and Amazon prime @NIRMALYA SASMAL just tell me one thing have u watched the whole speach it\\'s\\njust 4-5 min u should watch it. I agree with you but I have a point too. Before elaborating my point, I want\\nto let you know that I\\'m here after seeing the \"Joker Movie analysis\". I\\nfirmly believe the male character in Kabir Singh was irresponsible and doesn\\'t\\nhave any reflection with real life or practicality. As you said in the later\\npart of this video, \"if you\\'re in relationship and your partner is self\\nderogating then run as fast as possible.\" Don\\'t you think this line defy your\\nJoker analysis, where you appraised/empathize Joker\\'s mental state and called\\nthe movie INCREDIBLE. But in this part you said to run ftom such type of\\nperson, if we all keep running from person who\\'re mentally ill then were would\\nour generation will end up. I\\'m not saying this all because I like Kabir\\nSingh, I\\'m saying this because I have depression, anxiety and personality\\ndisorder. In the movie \"principal\" told the class about his Anger management\\nissue.\\nKabir also has emotional/mental issues but I guess you didn\\'t observed him\\nprecisely as much as you observed Joker. As per WHO, one in every 20 Indian\\nsuffer from depression; 5 out of 100.\\nHope you understand what I\\'m trying to say. Peace ☮️ @mala sahu India is a failed state and so do NSA , you cant scare us with your\\n\"Nazi Gestapo\" crap @sonali roy r8 **shahid fans hit like 😍😍** Great Job ! Hitesh Kumar see here in youtube some misandrists are commenting using fake\\nI\\'d.Some female misandrists are a snake of two face that means they says that\\n498 must be banned but they work for developing laws against men.This type of\\nmisandrists are just a spy of radical misandrists.They are doing drama of\\ngender equality at daylight but at a secure time they change their form.Those\\nare the misandrists in the coat of gender [equality.Be](http://equality.be/)\\ncareful from them and try to identify them.They just watching us to provide\\nthe informations to the local misandrists in the form of gender\\n[equality.Like](http://equality.like/) a spy uses beard so that he cannot be\\nidentified.Sometimes those misandrists make id using photo and name of the\\nboys Let AR use her name as range & billa and fill the same name when applying for\\nher Visa to any overseas countries  \\nWhy our govt is napunsak and not revoke her passport/visa or even arrest her Bhai good analysis Super boss arnab you must retire now. you are done. Best review. Khup negatives reviews milale Kabir singh la.. Filmi corporation\\nchya Suchitra tyagi tar Vish okalay tichya review madhe.. Go to masses man..\\nMovie is getting excellent response from people.. This type of love story is\\nencouraging in today\\'s world where one night stand and extra martial affair is\\ncomon @Naveen Shekhar I know that\\'s exactly what I said . Hi iam from Odisha state bhubaneswar 09777070288 I want make friendship with\\nyou and meet with you if you are interested msg me on whatsapp and call me let\\nsee 7 mine Seriously so sad to say but ... Tatti movie @aam admi ok Exactly these assholic memers posted piles of shit memes on social media about\\nthis absolutely rubbish and nonsensical film , I can\\'t even call it a film\\nsuch directors should stop making movies asap otherwise already shitty\\nbollywood is going to become even more shittier This is really a good 1🤗🤗🤗🤗🤗 No nice video 👨\\u200d❤️\\u200d💋\\u200d👨👨\\u200d❤️\\u200d💋\\u200d👨👨\\u200d❤️\\u200d💋\\u200d👨👨\\u200d❤️\\u200d💋\\u200d👨 Ranu is a I love u sakib but opu sotiya Salute You bhai.... Your best review till now... Dho dala... Love u I studied really hard the next few days after watching this movie😂 If I shoot her, will l be jailed or I can get away with that? Pratik bhaiya l want to ask you something I cannot understand how a government is sparing a antinational element\\nArundhati Roy ? Her this coment is enough to be prosecuted in NIA . Nice video 😘😘😘😘 Govt official take census at arundhati Roy\\'s house.. what is your name maam\\n..roy says- my name is cunning bitch. Just when i was thinking wrong you just made my mind clear. Thank you. Disgusting Justice served.... Not thanks to God.Only thanks to you dada Arnab don\\'t give more important to Mrs.Roy. Just take her in custody and\\ndemonstrate law exist Lotous come out from mud but it is expected it must be shunned the stink of\\nmud. Good.... Hahhaaa Nailed it ...outstanding reply to film companion and others Super vai @Arnab: Do you know what are the plans of Govt with the Illegal immigrants?\\nHow would a refugee prove religious persecution? Why have we shown selective\\ncompassion?  \\nDo you really think it is the right time for India to do an activity like NRC\\ngiven the facts that almost 20% population are below poverty line and 30% of\\nadult population are still illiterate which constitutes more than 50% Women\\nwho are still deprived of their basic needs. Do you think, this is the time\\nsuch exercise would be of any beneficial to India? Don\\'t you think the CJI and\\nGOI has wasted our huge 16K Cr rupees in this unsuccessful exercise and if we\\nlive the money aside, look at the extent of trouble and pain people went in\\nAssam due to this.  \\nThe reason I Pointed to NRC is because NPR is nothing but Opening Step of NRC\\nand with reference to Scroll.in(correct me if I am wrong) the new questions\\nadded to NPR are indicators of the NRC exclusion process.  \\nYou being a Journalist and from Assam, doesn\\'t this pinches your heart and\\nraises alarm. Is there no value of human life on this land anymore?  \\n  \\nI strongly Oppose NRC, Oppose CAA amendment in the current situation.  \\nWas there any effective effort from GOI to stop the infiltration?  \\n  \\nGOI is just find ways to treat us like goats every now and then.  \\n  \\nI know, this questions should be thrown at GOI, however, as I see you a so\\ncalled representative of the GOI most of the time, so, I am throwing this on\\nyou.  \\nMoreover, whats wrong with you getting stuck in this stupid debates on who\\ntold what. Everyone around us promote lies everyday. Nobody really bothers\\nthat anymore. Starting from PM to HM to Activist everyone promotes lies\\neverywhere but no facts. So, Arundhati is no different, where we cannot trust\\nthe PM/CJI for that matter, who is Arundhati in that league. No one cares\\nabout her. I stopped watching your channel, just thought of looking over today\\nfor a change, but nothing changed. Same insensitive arguments and false\\nnarratives. I wish I could say alternate narratives, but I see them clearly to\\nbe false.  \\nAlso JFYI, I supported the change in Govt, but really regretting now. I dont\\nsupport any political party anymore. So, please dont ask me why didn\\'t I speak\\nduring UPA rule. I dont have to answer that to you. Good job bro 🤘❤✌ Thanks brother for your good explanation . NICE Shirt Pratik Bhai 😂 She is social pollutant  \\nShe should be arrested as quick as possible I lov ur video dada. ...... This movie hits at people\\'s Mesmorism about a king... Because he is a king he\\nis justified being doing all Good job. This movie was total shit... Nice review .. can i get a like Wow amazing videos your are no Santa Claus Very good... throw out these homosexuals out of India... bloody rouge.. bloody\\nSC deteriorating Indian culture... bann the SC first... bloody old gay\\njudges... I appreciate what you are saying.I will always support you  \\n  \\n  \\n  \\nwhatever it takes good job jahangir that\\'s is rong yarr This lady is the true face of urban naxal,and is paid by western countries and\\nisi to destroy india by giving provocative speech,she should be put behind\\nbars SUSSANE arundhati roy if you reading this comment So I want to suggest you a book named \"Incognito\\nwritten by david eagleman\"\\nits really great book you wont regreat reading it Thanku sir.... You\\'re awesome Ms.Roy should have been arrested immediately when she is enticing people in\\nthe public. Now, remember these English speaking monarchy minded Congress and hippocrate\\nCommunist have to polish shoes of common people and they will get room below\\nshoe to take rest. Check the news:  \\nA guy from TikTok name Ashwani Kumar murdered a flight attendant he was\\nobsessed with. He was uploading villain clips on social media imitating Kabir\\nSingh. Exactly bro...... you are absolutely right. I am with your thoughts. Please\\nkeep posting these kinda videos really appreciate your work Nice vedio You are absolutely right dada, Review Joker bro scary tube lol 🤣🤣🤣 @Anindita Maity nice sister... you are right @Its chakshank wlcm❤ Didn\\'t see a video so demeaning of lgbt and women alike... U guys should be\\nashamed! Which day n age r u living in? Hope I cud spam such videos. Even lgbt people have their own standards lol ...I\\'m gay but you will never\\nfind me drooling over boys in public for mere pleasure... And also I have a\\ntype. You really want to spoil such masterpieces? Alpha male is a pack builder not a timid destroyer who hides behind the mask\\nof masculinity... Yes only dumb girls who has extreme psychological issues\\nthemselves can fall in love with such a gross character !!! Codependencey is a\\nthing ... Kabir shing is a portrayal of toxic codependency only !!! A sane\\nindependent girl will run miles away as soon as she smells a Kabir shing ...\\nBut if she doesn\\'t and embresses the insane dominant dynamic then mere Bhai\\nyou both have deep rooted psychological issues and need immediate therapy ...\\nOtherwise together or not both are doomed my friend !! In my opinion if you\\neven like the character you need therapy ...  \\nAsk yourself what within you makes you like and imitate such a gross tatty\\ncharacter!! Very very problematic I. like you very nice Media and public Bengali film land of women public television series is a good Real man is someone who has purpose in his life. Purpose makes our lives\\nmeaningful. Nice Bro Your biggest ac Fuck feminism ! I love you brother for saying this on this platform. I completely agree with\\nyour thoughts. Omg what a retard Super!! Your right my friend Great job jahangir bhai Nice apu didi @Pratik Borade bro i have master\\'s degree in physics from IIT kgp. Seriously\\ndude you should reads books. I am not even laughing at you. I feel pity . I\\nfeel pity for myself for wasting my time on some dumb YouTuber. Hasi ka patra?\\nSome one pls just kill me I can\\'t take it anymore Hmm Kabir singh is synonymous to every rickshawallah who drink and and beat their\\nwife , are sex addicts , and sulk when their wives leave them. Wonder why\\npeople dont make movies on them From the depth of my Heart i like the way you observe things and share your\\npoint of views... this is my first comment please sir give Heart ☺ @Amritpal Singh yes Bollywood lionize shit I m thinking that u r reviewing a movie or just using it for poltical agenda. Jhand movie is the perfect word U r true bhaii Ni'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3364, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 128,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"evaluate_during_training\": False,\n",
    "    \"evaluate_during_training_steps\": 2000,\n",
    "    \"evaluate_during_training_verbose\": False,\n",
    "    \"use_cached_eval_features\": False,\n",
    "    \"save_eval_checkpoints\": True,\n",
    "    \"no_cache\": False,\n",
    "    \"save_model_every_epoch\": True,\n",
    "    \"tensorboard_dir\": None,\n",
    "\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": True,\n",
    "\n",
    "    \"process_count\": cpu_count() - 2 if cpu_count() > 2 else 1,\n",
    "    \"n_gpu\": 1,\n",
    "    \"silent\": False,\n",
    "    \"use_multiprocessing\": True,\n",
    "\n",
    "    \"wandb_project\": None,\n",
    "    \"wandb_kwargs\": {},\n",
    "\n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_delta\": 0,\n",
    "    \"early_stopping_metric\": \"eval_loss\",\n",
    "    \"early_stopping_metric_minimize\": True,\n",
    "\n",
    "    \"manual_seed\": None,\n",
    "    \"encoding\": None,\n",
    "    \"config\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForMultiLabelSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMultiLabelSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "model = MultiLabelClassificationModel('distilbert', 'distilbert-base-cased', num_labels=12, args = args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457079e031d34cc3aaf6cb670080670b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_df, show_running_loss = True)  # Takes considerable amount of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df) # Takes considerable amount of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(eval_df.shape[0])\n",
    "print(encoder.decode(torch.tensor(model_outputs[i].argmax()+1)))\n",
    "print(eval_df['text'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/outputs/checkpoint-5226-epoch-2 ./Cache/Models/DistilBERT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "model = MultiLabelClassificationModel('distilbert', 'distilbert-base-uncased', num_labels=24, args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df, show_running_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(eval_df.shape[0])\n",
    "print(encoder.decode(torch.tensor(model_outputs[i].argmax()+1)))\n",
    "print(eval_df['text'].values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "model = MultiLabelClassificationModel('roberta', 'distilroberta-base', num_labels=12, args = args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df, show_running_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(eval_df.shape[0])\n",
    "print(encoder.decode(torch.tensor(model_outputs[i].argmax()+1)))\n",
    "print(eval_df['text'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './Cache/Models/RoBERTA/model_roberta_4.h5')\n",
    "torch.save(model.state_dict(), './Cache/Models/RoBERTA/model_roberta_6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(eval_df.shape[0])\n",
    "print(encoder.decode(torch.tensor(model_outputs[i].argmax()+1)))\n",
    "print(eval_df['text'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/outputs/checkpoint-2613-epoch-1 ./Cache/Models/DistilBERT/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "model = MultiLabelClassificationModel('albert', 'albert-large-v1', num_labels=12, args = args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df, show_running_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def roc_curve(y_score=model_outputs, y_test=y_test, n_classes = 12, col=2):\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "for col in range(12):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[col], tpr[col], color='darkorange',\n",
    "          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[col])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Flair: ' + str(encoder.decode(torch.tensor(col+1))))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./Cache/Figures/DistilBERT/' + str(col+1) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
