{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas                       as pd\n",
    "import numpy                        as np\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection        import train_test_split\n",
    "from sklearn.metrics                import accuracy_score, classification_report, confusion_matrix\n",
    "import scikitplot.metrics            as skplot\n",
    "\n",
    "import tensorflow                   as tf\n",
    "import tensorflow_hub               as hub\n",
    "\n",
    "import bert\n",
    "from bert                           import run_classifier\n",
    "from bert                           import optimization\n",
    "from bert                           import tokenization\n",
    "from pathlib                        import Path\n",
    "from HindiTokenizer                 import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/cleaned hindi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "      <th>normalized lexicon</th>\n",
       "      <th>monolingual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C4.131</td>\n",
       "      <td>Bollywood film dekhne ke samay logic ghar mein...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§´‡§º‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§§‡§∞‡•ç‡§ï ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ö‡•ã‡§∞ ‡§Æ‡§æ...</td>\n",
       "      <td>‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§´‡§º‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡§®‡•á ‡§∏‡§Æ‡§Ø ‡§§‡§∞‡•ç‡§ï ‡§Æ‡•á‡§Ç ‡§ö‡•ã‡§∞ ‡§Æ‡§æ‡§Ç ‡§ù‡•Å‡§Ç‡§°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4.638</td>\n",
       "      <td>Chutiya movie...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§ö‡§≤‡§ö‡§ø‡§§‡•ç‡§∞...</td>\n",
       "      <td>‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§ö‡§≤‡§ö‡§ø‡§§‡•ç‡§∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C38.598</td>\n",
       "      <td>Us jaat bnde ka khene ka matlab tha mar daluga...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§π‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ü ‡§¨‡§Ç‡§¶‡•á ‡§ï‡§æ ‡§ï‡§π‡§®‡•á ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§•‡§æ ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§°‡§æ‡§≤‡•Ç‡§ó‡§æ...</td>\n",
       "      <td>‡§π‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ü ‡§¨‡§Ç‡§¶‡•á ‡§ï‡§π‡§®‡•á ‡§Æ‡§§‡§≤‡§¨ ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§°‡§æ‡§≤‡•Ç‡§ó‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§™‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.2101.1</td>\n",
       "      <td>@Feminism Is CANCER *un feminist yeh sahi hai ...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>@feminism ‡§π‡•à ‡§ï‡•à‡§Ç‡§∏‡§∞ *‡§è ‡§®‡§æ‡§∞‡•Ä‡§µ‡§æ‡§¶‡•Ä ‡§Ø‡•á ‡§∏‡§π‡•Ä ‡§π‡•à ‡§™‡§∞‡§Ç‡§§‡•Å...</td>\n",
       "      <td>feminism ‡§ï‡•à‡§Ç‡§∏‡§∞ ‡§®‡§æ‡§∞‡•Ä‡§µ‡§æ‡§¶‡•Ä ‡§∏‡§π‡•Ä ‡§™‡§∞‡§Ç‡§§‡•Å ‡§Æ‡§§‡§≤‡§¨ ‡§•‡•ã‡•ú‡•Ä ‡§∏‡§æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C29.14.2</td>\n",
       "      <td>Amrit Anand ‡§Ö‡§¨ ‡§§‡•ã ‡§ú‡•Å‡•ú‡•á ‡§π‡•Ä ‡§π‡•à ‡§â‡§®‡§ï‡•ã ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§Ö‡§Æ‡•É‡§§ ‡§Ü‡§®‡§Ç‡§¶ ‡§Ö‡§¨ ‡§§‡•ã ‡§ú‡•Å‡•ú‡•á ‡§π‡•Ä ‡§π‡•à ‡§â‡§®‡§ï‡•ã ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á</td>\n",
       "      <td>‡§Ö‡§Æ‡•É‡§§ ‡§Ü‡§®‡§Ç‡§¶ ‡§ú‡•Å‡•ú‡•á ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>C29.18</td>\n",
       "      <td>Are bhai konsi duniya mai rehate hoüòÇüòÇ</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§≠‡§æ‡§à ‡§ï‡•ã‡§®‡§∏‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§Æ‡§à ‡§∞‡§π‡§§‡•á hoüòÇüòÇ</td>\n",
       "      <td>‡§≠‡§æ‡§à ‡§ï‡•ã‡§®‡§∏‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§∞‡§π‡§§‡•á</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>C9.225</td>\n",
       "      <td>Sahi to bola</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§∏‡§π‡•Ä ‡§∏‡•á‡§µ‡§æ ‡§µ‡§π ‡§•‡•Ä</td>\n",
       "      <td>‡§∏‡§π‡•Ä ‡§∏‡•á‡§µ‡§æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>C7.1685</td>\n",
       "      <td>Or tum Kay Kar raya ho?</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§Ø‡§æ ‡§§‡•Å‡§Æ kay ‡§ï‡§∞ ‡§∞‡§æ‡§Ø‡§æ ‡§π‡•ã?</td>\n",
       "      <td>‡§§‡•Å‡§Æ kay ‡§∞‡§æ‡§Ø‡§æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>C36.692.1</td>\n",
       "      <td>Ye bhaat sahi hain par zyada dhin thine ga nah...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§π‡§æ‡§Å ‡§ö‡§æ‡§µ‡§≤ sahi ‡§π‡•à‡§Ç ‡§™‡§∞ ‡•õ‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§Æ‡§∞‡§®‡§æ ‡§§‡•á‡§∞‡§æ ‡§™‡§∞‡§Ç‡§§‡•Å ‡§®‡§π...</td>\n",
       "      <td>‡§π‡§æ‡§Å ‡§ö‡§æ‡§µ‡§≤ sahi ‡•õ‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§Æ‡§∞‡§®‡§æ ‡§§‡•á‡§∞‡§æ ‡§™‡§∞‡§Ç‡§§‡•Å ‡§ï‡§π‡§æ‡§Å ‡§ñ‡•Å‡§¶‡§æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>C4.1202</td>\n",
       "      <td>Islye maine Kabaad singh nai dekha..</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>‡§á‡§∏‡§≤‡§ø‡§è ‡§Æ‡•à‡§Ç‡§®‡•á kabaad ‡§∏‡§ø‡§Ç‡§π ‡§Ö‡§®‡•Å‡§™‡§∏‡•ç‡§•‡§ø‡§§ ‡§¶‡•á‡§ñ‡§æ..</td>\n",
       "      <td>‡§á‡§∏‡§≤‡§ø‡§è ‡§Æ‡•à‡§Ç‡§®‡•á kabaad ‡§∏‡§ø‡§Ç‡§π ‡§Ö‡§®‡•Å‡§™‡§∏‡•ç‡§•‡§ø‡§§ ‡§¶‡•á‡§ñ‡§æ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4981 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "0        C4.131  Bollywood film dekhne ke samay logic ghar mein...        NAG   \n",
       "1        C4.638                                   Chutiya movie...        NAG   \n",
       "2       C38.598  Us jaat bnde ka khene ka matlab tha mar daluga...        OAG   \n",
       "3     C4.2101.1  @Feminism Is CANCER *un feminist yeh sahi hai ...        OAG   \n",
       "4      C29.14.2       Amrit Anand ‡§Ö‡§¨ ‡§§‡•ã ‡§ú‡•Å‡•ú‡•á ‡§π‡•Ä ‡§π‡•à ‡§â‡§®‡§ï‡•ã ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á        NAG   \n",
       "...         ...                                                ...        ...   \n",
       "4976     C29.18              Are bhai konsi duniya mai rehate hoüòÇüòÇ        NAG   \n",
       "4977     C9.225                                       Sahi to bola        NAG   \n",
       "4978    C7.1685                            Or tum Kay Kar raya ho?        NAG   \n",
       "4979  C36.692.1  Ye bhaat sahi hain par zyada dhin thine ga nah...        NAG   \n",
       "4980    C4.1202               Islye maine Kabaad singh nai dekha..        NAG   \n",
       "\n",
       "     Sub-task B                                 normalized lexicon  \\\n",
       "0          NGEN  ‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§´‡§º‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§§‡§∞‡•ç‡§ï ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ö‡•ã‡§∞ ‡§Æ‡§æ...   \n",
       "1          NGEN                                  ‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§ö‡§≤‡§ö‡§ø‡§§‡•ç‡§∞...   \n",
       "2          NGEN  ‡§π‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ü ‡§¨‡§Ç‡§¶‡•á ‡§ï‡§æ ‡§ï‡§π‡§®‡•á ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§•‡§æ ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§°‡§æ‡§≤‡•Ç‡§ó‡§æ...   \n",
       "3          NGEN  @feminism ‡§π‡•à ‡§ï‡•à‡§Ç‡§∏‡§∞ *‡§è ‡§®‡§æ‡§∞‡•Ä‡§µ‡§æ‡§¶‡•Ä ‡§Ø‡•á ‡§∏‡§π‡•Ä ‡§π‡•à ‡§™‡§∞‡§Ç‡§§‡•Å...   \n",
       "4          NGEN         ‡§Ö‡§Æ‡•É‡§§ ‡§Ü‡§®‡§Ç‡§¶ ‡§Ö‡§¨ ‡§§‡•ã ‡§ú‡•Å‡•ú‡•á ‡§π‡•Ä ‡§π‡•à ‡§â‡§®‡§ï‡•ã ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á   \n",
       "...         ...                                                ...   \n",
       "4976       NGEN           ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§≠‡§æ‡§à ‡§ï‡•ã‡§®‡§∏‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§Æ‡§à ‡§∞‡§π‡§§‡•á hoüòÇüòÇ   \n",
       "4977       NGEN                                     ‡§∏‡§π‡•Ä ‡§∏‡•á‡§µ‡§æ ‡§µ‡§π ‡§•‡•Ä   \n",
       "4978       NGEN                             ‡§Ø‡§æ ‡§§‡•Å‡§Æ kay ‡§ï‡§∞ ‡§∞‡§æ‡§Ø‡§æ ‡§π‡•ã?   \n",
       "4979       NGEN  ‡§π‡§æ‡§Å ‡§ö‡§æ‡§µ‡§≤ sahi ‡§π‡•à‡§Ç ‡§™‡§∞ ‡•õ‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§Æ‡§∞‡§®‡§æ ‡§§‡•á‡§∞‡§æ ‡§™‡§∞‡§Ç‡§§‡•Å ‡§®‡§π...   \n",
       "4980       NGEN           ‡§á‡§∏‡§≤‡§ø‡§è ‡§Æ‡•à‡§Ç‡§®‡•á kabaad ‡§∏‡§ø‡§Ç‡§π ‡§Ö‡§®‡•Å‡§™‡§∏‡•ç‡§•‡§ø‡§§ ‡§¶‡•á‡§ñ‡§æ..   \n",
       "\n",
       "                                            monolingual  \n",
       "0     ‡§¨‡•â‡§≤‡•Ä‡§µ‡•Å‡§° ‡§´‡§º‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡§®‡•á ‡§∏‡§Æ‡§Ø ‡§§‡§∞‡•ç‡§ï ‡§Æ‡•á‡§Ç ‡§ö‡•ã‡§∞ ‡§Æ‡§æ‡§Ç ‡§ù‡•Å‡§Ç‡§°...  \n",
       "1                                        ‡§ö‡•Å‡§ü‡§ø‡§Ø‡§æ ‡§ö‡§≤‡§ö‡§ø‡§§‡•ç‡§∞  \n",
       "2     ‡§π‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ü ‡§¨‡§Ç‡§¶‡•á ‡§ï‡§π‡§®‡•á ‡§Æ‡§§‡§≤‡§¨ ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§°‡§æ‡§≤‡•Ç‡§ó‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§™‡§∞...  \n",
       "3     feminism ‡§ï‡•à‡§Ç‡§∏‡§∞ ‡§®‡§æ‡§∞‡•Ä‡§µ‡§æ‡§¶‡•Ä ‡§∏‡§π‡•Ä ‡§™‡§∞‡§Ç‡§§‡•Å ‡§Æ‡§§‡§≤‡§¨ ‡§•‡•ã‡•ú‡•Ä ‡§∏‡§æ...  \n",
       "4                             ‡§Ö‡§Æ‡•É‡§§ ‡§Ü‡§®‡§Ç‡§¶ ‡§ú‡•Å‡•ú‡•á ‡§¨‡•ã‡§≤‡•ã ‡§ú‡•Å‡•ú‡§®‡•á  \n",
       "...                                                 ...  \n",
       "4976                              ‡§≠‡§æ‡§à ‡§ï‡•ã‡§®‡§∏‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§∞‡§π‡§§‡•á  \n",
       "4977                                           ‡§∏‡§π‡•Ä ‡§∏‡•á‡§µ‡§æ  \n",
       "4978                                       ‡§§‡•Å‡§Æ kay ‡§∞‡§æ‡§Ø‡§æ  \n",
       "4979  ‡§π‡§æ‡§Å ‡§ö‡§æ‡§µ‡§≤ sahi ‡•õ‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§Æ‡§∞‡§®‡§æ ‡§§‡•á‡§∞‡§æ ‡§™‡§∞‡§Ç‡§§‡•Å ‡§ï‡§π‡§æ‡§Å ‡§ñ‡•Å‡§¶‡§æ...  \n",
       "4980             ‡§á‡§∏‡§≤‡§ø‡§è ‡§Æ‡•à‡§Ç‡§®‡•á kabaad ‡§∏‡§ø‡§Ç‡§π ‡§Ö‡§®‡•Å‡§™‡§∏‡•ç‡§•‡§ø‡§§ ‡§¶‡•á‡§ñ‡§æ  \n",
       "\n",
       "[4981 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['monolingual'] = df['monolingual'].apply(lambda w : str(w).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {'NAG' : 0, 'OAG' : 1, 'CAG' : 2}\n",
    "df = df.replace({'Sub-task A' : label_encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42) # HANDLE TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "DATA_COLUMN = 'Text'\n",
    "LABEL_COLUMN = 'Sub-task A'\n",
    "label_list = df['Sub-task A'].unique() # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9390d305b21494ca4c29a803af4f82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=572.0, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f83be3807d4b518d75bd50a668ae4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=606915.0, style=ProgressStyle(descripti‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db992877ad924bc9bb2baf130b250c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1129dccf1b742948b8a1e50ac861ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=181.0, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37978db44d29485b861f3e768b9c518a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=58908041.0, style=ProgressStyle(descrip‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monsoon-nlp/hindi-bert\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"monsoon-nlp/hindi-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Writing example 0 of 3984\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] ‡§Ø‡•á ‡§≤‡•ã‡§ó ‡§∏‡§Ç‡§ú‡•Ç ‡§ú‡•à‡§∏‡•Ä ‡§Æ‡•Ç‡§µ‡•Ä ‡§ï‡•Ä ‡§ñ‡•Ç‡§¨ ‡§§‡§æ‡§∞‡•Ä‡§´ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§≤‡•á‡§ï‡§ø‡§® ‡§ï‡§¨‡•Ä‡§∞ ‡§∏‡§ø‡§Ç‡§π ‡§ú‡•ã ‡§ï‡§ø ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§ï‡§π‡§æ‡§®‡•Ä ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§â‡§∏‡§∏‡•á [UNK] ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡•§ [SEP]\n",
      "INFO:tensorflow:input_ids: 3 2349 2189 36654 4188 13366 1898 5885 30571 2156 1917 2294 9584 2571 1975 1952 3184 2370 6764 3605 1912 3147 4143 0 2324 1917 507 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] ka ##b ##ir pre ##et ##i k ##o k ##uch ##h or ka ##r ##ne hi n ##i det ##a l ##ol or is ##ki to k ##oi b ##a ##at hi n ##i ka ##r r ##ha ##or ab bh ##ai ne w ##oh ##i b ##ola j ##o me so ##ch r ##ha th ##a n ##ice rev ##iew [SEP]\n",
      "INFO:tensorflow:input_ids: 3 25049 1095 4739 17997 3790 1022 79 1020 79 14380 1081 5307 25049 1019 10908 36591 82 1022 25048 1024 80 3529 5307 5888 30321 4929 79 30180 70 1024 2558 36591 82 1022 25049 1019 86 13668 2624 12026 28893 9129 17996 91 13187 1022 70 30230 78 1020 11586 17911 3702 86 13668 5099 1024 82 9550 34115 24224 4 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] @ R ##ish ##ita Pan ##de ##y : to ##h t ##um e ##k k ##ut ##te K ##i b ##ac ##chi H ##o ? [SEP]\n",
      "INFO:tensorflow:input_ids: 3 36 54 8211 30365 38022 24340 1028 30 4929 1081 88 4413 73 1070 79 4616 13795 47 1022 70 5779 27093 44 1020 35 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] Bh ##ai a ##aj f ##ull form m h I ##k hi di ##n m 3 - 3 v ##ide ##o [UNK] [SEP]\n",
      "INFO:tensorflow:input_ids: 3 16483 9129 69 9480 74 19681 5238 81 76 45 1070 36591 30955 1051 81 23 17 23 90 10416 1020 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] k ##oi k ##uc ##ch v kh ##e m ##uj ##he film f ##a ##ad ##u l ##g ##i [SEP]\n",
      "INFO:tensorflow:input_ids: 3 79 30180 79 8955 3702 90 31747 1026 81 26510 2787 30933 74 1024 4404 1067 80 1068 1022 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Writing example 0 of 997\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] Bh ##ai ap n ##a m ##j ##he b ##d ##l di ##ya hai . [SEP]\n",
      "INFO:tensorflow:input_ids: 3 16483 9129 24692 82 1024 81 1124 2787 70 1069 1027 30955 12059 21603 18 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] Bh ##ai ##y ##o Ar ##und ##ha ##ti R ##oy k ##o m ##a ##af ka ##ro , E A ##ura ##t sh ##ub ##h sh ##ub ##ha 90 m ##a ##ark ##e a ##ay ##i , [UNK] ar ##res ##t h ##og ##a e aur ##at b ##ole ##g ##a ki m ##ai n ##ash ##e me th ##i . [SEP]\n",
      "INFO:tensorflow:input_ids: 3 16483 9129 1028 1020 9726 10859 13668 17738 54 13507 79 1020 81 1024 18076 25049 3648 16 41 37 24555 1025 10610 6718 1081 10610 6718 13668 6574 81 1024 14149 1026 69 4553 1022 16 0 6959 28188 1025 76 4966 1024 73 34886 2558 70 13416 1068 1024 26196 81 9129 82 12610 1026 11586 5099 1022 18 4 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] Y ##eh ##i la ##und ##a b ##ach ##a sa ##kt ##a hai is gen ##eration k ##o [SEP]\n",
      "INFO:tensorflow:input_ids: 3 61 34231 1022 21291 10859 1024 70 9809 1024 30164 38348 1024 21603 5888 18167 23416 79 1020 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] Bh ##ai m ##uj ##e u ##uss j ##a ##at ka number ch ##ai ##ye y ##r [SEP]\n",
      "INFO:tensorflow:input_ids: 3 16483 9129 81 26510 1026 89 26656 78 1024 2558 25049 20359 8154 9129 30976 93 1019 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] K ##ab ##ir [UNK] [SEP]\n",
      "INFO:tensorflow:input_ids: 3 47 5615 4739 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# set sequences, \n",
    "# look here for more info - https://github.com/google-research/bert/blob/master/README.md#out-of-memory-issues\n",
    "MAX_SEQ_LENGTH = 64\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(\n",
    "        BERT_MODEL_HUB,\n",
    "        trainable=True)\n",
    "    bert_inputs = dict(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "        inputs=bert_inputs,\n",
    "        signature=\"tokens\",\n",
    "        as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(\n",
    "            tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "\n",
    "\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics.\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                  loss=loss,\n",
    "                                                  train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                  loss=loss,\n",
    "                                                  eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 50.0\n",
    "# Warmup is a period of time where the learning rate \n",
    "# is small and gradually increase; usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '../Cache/Models/BERT-Hindi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../Cache/Models/BERT-Hindi/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6840beb0d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT-Hindi/model.ckpt-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT-Hindi/model.ckpt-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ../Cache/Models/BERT-Hindi/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ../Cache/Models/BERT-Hindi/model.ckpt.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[62,2,0] = 34115 is not in [0, 30522)\n\t [[node module_apply_tokens/bert/embeddings/embedding_lookup (defined at /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'module_apply_tokens/bert/embeddings/embedding_lookup':\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-1eb71a2fa1b7>\", line 3, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-db1817b12c66>\", line 20, in model_fn\n    (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n  File \"<ipython-input-16-40a118e33f7a>\", line 14, in create_model\n    as_dict=True)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_hub/module.py\", line 266, in __call__\n    name=name)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_hub/native_module.py\", line 610, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 1453, in import_meta_graph\n    **kwargs)[0]\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[62,2,0] = 34115 is not in [0, 30522)\n\t [[{{node module_apply_tokens/bert/embeddings/embedding_lookup}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1eb71a2fa1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Beginning Training!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1194\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1260\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         logging.info(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[62,2,0] = 34115 is not in [0, 30522)\n\t [[node module_apply_tokens/bert/embeddings/embedding_lookup (defined at /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'module_apply_tokens/bert/embeddings/embedding_lookup':\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-1eb71a2fa1b7>\", line 3, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-db1817b12c66>\", line 20, in model_fn\n    (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n  File \"<ipython-input-16-40a118e33f7a>\", line 14, in create_model\n    as_dict=True)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_hub/module.py\", line 266, in __call__\n    name=name)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_hub/native_module.py\", line 610, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 1453, in import_meta_graph\n    **kwargs)[0]\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-10-28T19:55:49Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-10-28T19:55:49Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-10-28-19:57:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-10-28-19:57:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3330: eval_accuracy = 0.91369605, false_negatives = 47.0, false_positives = 34.0, global_step = 3330, loss = 0.4298469, true_negatives = 806.0, true_positives = 179.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3330: eval_accuracy = 0.91369605, false_negatives = 47.0, false_positives = 34.0, global_step = 3330, loss = 0.4298469, true_negatives = 806.0, true_positives = 179.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3330: ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3330: ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.91369605,\n",
       " 'false_negatives': 47.0,\n",
       " 'false_positives': 34.0,\n",
       " 'loss': 0.4298469,\n",
       " 'true_negatives': 806.0,\n",
       " 'true_positives': 179.0,\n",
       " 'global_step': 3330}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "    labels = ['NAG', 'OAG', 'CAG']\n",
    "    input_examples = [run_classifier.InputExample(\n",
    "        guid=\"\", text_a=x, text_b=None, label=0) for x in in_sentences]  # here, \"\" is just a dummy label\n",
    "    input_features = run_classifier.convert_examples_to_features(\n",
    "        input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(\n",
    "        features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = list(test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] best reply to feminist ##s & liberals . . . . . ! ! [ # ka ##bir ##sing ##h ] ( http : / / www . youtube . com / results ? search _ query = % 23 ##ka ##bir ##sing ##h ) is a best movie . . . . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] best reply to feminist ##s & liberals . . . . . ! ! [ # ka ##bir ##sing ##h ] ( http : / / www . youtube . com / results ? search _ query = % 23 ##ka ##bir ##sing ##h ) is a best movie . . . . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2190 7514 2000 10469 2015 1004 13350 1012 1012 1012 1012 1012 999 999 1031 1001 10556 17706 7741 2232 1033 1006 8299 1024 1013 1013 7479 1012 7858 1012 4012 1013 3463 1029 3945 1035 23032 1027 1003 2603 2912 17706 7741 2232 1007 2003 1037 2190 3185 1012 1012 1012 1012 102 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2190 7514 2000 10469 2015 1004 13350 1012 1012 1012 1012 1012 999 999 1031 1001 10556 17706 7741 2232 1033 1006 8299 1024 1013 1013 7479 1012 7858 1012 4012 1013 3463 1029 3945 1035 23032 1027 1003 2603 2912 17706 7741 2232 1007 2003 1037 2190 3185 1012 1012 1012 1012 102 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] nice , , , , , [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] nice , , , , , [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3835 1010 1010 1010 1010 1010 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3835 1010 1010 1010 1010 1010 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] agree ##e [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] agree ##e [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5993 2063 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5993 2063 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] nice good job [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] nice good job [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3835 2204 3105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3835 2204 3105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ pr ##ati ##k bo ##rade sorry brother so write such comment because something similar happened in my life also in past but is ending is very different in real life . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] @ pr ##ati ##k bo ##rade sorry brother so write such comment because something similar happened in my life also in past but is ending is very different in real life . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 10975 10450 2243 8945 13662 3374 2567 2061 4339 2107 7615 2138 2242 2714 3047 1999 2026 2166 2036 1999 2627 2021 2003 4566 2003 2200 2367 1999 2613 2166 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1030 10975 10450 2243 8945 13662 3374 2567 2061 4339 2107 7615 2138 2242 2714 3047 1999 2026 2166 2036 1999 2627 2021 2003 4566 2003 2200 2367 1999 2613 2166 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cache/Models/BERT/model.ckpt-3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = getPrediction(pred_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(predictions)\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "predicted_sentiment = []\n",
    "for i in range(len(predictions)):\n",
    "    texts.append(predictions[i][0])\n",
    "    predicted_sentiment.append(predictions[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {'Text' : texts, 'predicted_label' : predicted_sentiment}\n",
    "output_df = pd.DataFrame(output_dict)\n",
    "output_df = output_df.replace({'predicted_label' : label_encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel('output/output_bert.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is : 76.31887456037515 %\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(output_df['predicted_label'], test[LABEL_COLUMN])\n",
    "print(\"The test accuracy is : {} %\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       840\n",
      "           1       0.05      0.06      0.06       105\n",
      "           2       0.05      0.04      0.04       121\n",
      "\n",
      "    accuracy                           0.77      1066\n",
      "   macro avg       0.35      0.35      0.35      1066\n",
      "weighted avg       0.76      0.77      0.76      1066\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplot.plot_confusion_matrix(test[LABEL_COLUMN], output_df['predicted_label'])\n",
    "print(classification_report(test[LABEL_COLUMN], output_df['predicted_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
